{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.data import Dataset\nimport matplotlib.pyplot as plt\n# pip install seaborn\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, Normalizer\nimport re\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n%config InlineBackend.figure_format = 'retina'\npd.set_option(\"display.precision\", 2)\n\n# For facets\nfrom IPython.core.display import display, HTML\nimport base64\n!pip install facets-overview\nfrom facets_overview.feature_statistics_generator import FeatureStatisticsGenerator\n\nBASE_DIR = '/kaggle/input/spaceship-titanic'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-21T16:52:13.647361Z","iopub.execute_input":"2022-07-21T16:52:13.647810Z","iopub.status.idle":"2022-07-21T16:52:36.634514Z","shell.execute_reply.started":"2022-07-21T16:52:13.647719Z","shell.execute_reply":"2022-07-21T16:52:36.633270Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\nCollecting facets-overview\n  Downloading facets_overview-1.0.0-py2.py3-none-any.whl (24 kB)\nRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (1.3.5)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (1.21.6)\nRequirement already satisfied: protobuf>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (3.19.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.22.0->facets-overview) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.22.0->facets-overview) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.22.0->facets-overview) (1.16.0)\nInstalling collected packages: facets-overview\nSuccessfully installed facets-overview-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#@title Define Function to Visualize Binary Confusion Matrix\ndef plot_confusion_matrix(\n    confusion_matrix, class_names, subgroup, figsize = (8,6)):\n  # We're taking our calculated binary confusion matrix that's already in the \n  # form of an array and turning it into a pandas DataFrame because it's a lot \n  # easier to work with a pandas DataFrame when visualizing a heat map in \n  # Seaborn.\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n\n    rcParams.update({\n      'font.family':'sans-serif',\n      'font.sans-serif':['Liberation Sans'],\n    })\n  \n    sns.set_context(\"notebook\", font_scale=1.25)\n\n    fig = plt.figure(figsize=figsize)\n\n    plt.title('Confusion Matrix for Performance Across ' + subgroup)\n\n    # Combine the instance (numercial value) with its description\n    strings = np.asarray([['True Positives', 'False Negatives'],\n                          ['False Positives', 'True Negatives']])\n    labels = (np.asarray(\n        [\"{0:g}\\n{1}\".format(value, string) for string, value in zip(\n            strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n\n    heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\", \n        linewidths=2.0, cmap=sns.color_palette(\"GnBu_d\"));\n    heatmap.yaxis.set_ticklabels(\n        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n    heatmap.xaxis.set_ticklabels(\n        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n    plt.ylabel('References')\n    plt.xlabel('Predictions')\n    return fig\n\ndef process_drop_columns(df, columns):    \n    new_df = df.drop(columns=columns, axis=1, errors='ignore')\n    return new_df\n\ndef proces_boolean(df, columns):\n    for col in columns:\n        df[col] = [1 if x is True else 0 for x in df[col]]\n    return df\n\ndef process_categorical(df, columns):         \n    le = LabelEncoder()\n    label_object = {}\n    for col in columns:\n        labelencoder = LabelEncoder()\n        labelencoder.fit(df[col])\n        df[col] = labelencoder.fit_transform(df[col])\n        label_object[col] = labelencoder\n    return df\n\ndef create_hash(df):\n    df['Hash'] = df['Surname'].apply(lambda x: hash(tuple(x)))\n    return df\n\ndef processCabin(df):\n    df['Cabin'].replace('\\/\\d+\\/', '/', regex=True, inplace=True)\n    return df\n\ndef processName(df):\n    df['Surname'] = df['Name'].apply(lambda item: item.split(\" \")[1])\n    return df\n\ndef createTrainEvalSets(df):\n    df1 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) < 3]\n    df2 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) >= 3]\n    return (df1, df2)\n# train_df = processCabin(train_df)\n\n#slower\ndef fillAmenityAmount2(df, columns):    \n    for col in df.T.columns:\n        df.T[col].fillna(9, inplace=True)\n    return df  \n    \n    \ndef displayRowsWithNulls(df, columns):\n    display(df[columns][df[columns].isnull().any(axis=1)])\n\ndef process_normalize_columns(df, columns):\n    for col in columns:\n        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n    return df\n\ndef fillAmenityAmount(df, columns, regressor):   \n    df1=df[df[columns].isnull().any(axis=1)][columns]    \n    for index, row in df1.iterrows():              \n        features = df1.loc[index, ~pd.isna(row)]\n        \n        if(len(features) < 4):\n            arr = features.to_numpy()\n            arr = np.append(arr, 0)\n            features = pd.Series(arr).to_numpy()\n        features = np.array(features[..., np.newaxis])     \n        \n        prediction = regressor.predict(features.T)\n        col_name = df1.columns[pd.isna(row)][0]\n        \n        df.loc[index, col_name] = prediction[0]   \n    \n    return df\n\ndef fillHomePlanet(df, regressor):    \n    df1=df[df['HomePlanet'].isna()][['Cabin', 'HomePlanet']]\n    for index, row in df1.iterrows():   \n        \n        features = np.array(df1.loc[index, 'Cabin']) \n        features = features[..., np.newaxis]\n        \n        prediction = regressor.predict(features)\n        \n        df.loc[index, 'HomePlanet'] = np.argmax(prediction[0])   \n    \n    return df\n\ndef displayFacetStatistics(df):\n    fsg = FeatureStatisticsGenerator()\n    dataframes = [\n        {'table': df, 'name': 'trainData'}]\n    spaceshipProto = fsg.ProtoFromDataFrames(dataframes)\n    protostr = base64.b64encode(spaceshipProto.SerializeToString()).decode(\"utf-8\")\n\n\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-overview id=\"elem\"></facets-overview>\n            <script>\n              document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(protostr=protostr)\n    display(HTML(html))\n    \ndef displayFacetsDive(df):\n    SAMPLE_SIZE = 5000 #@param\n    df.dropna(how=\"any\", axis=0, inplace=True)\n    train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n            <script>\n              var data = {jsonstr};\n              document.querySelector(\"#elem\").data = data;\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(jsonstr=train_dive)\n    display(HTML(html))\n    \ndef createRegressor(data, features, label):    \n    class myRegressor(tf.keras.Model):\n        def __init__(self):\n            super().__init__()        \n            self.dense1 = Dense(1, activation='relu')  \n            #self.dense2 = Dense(2, activation='relu')         \n            self.dense3 = Dense(1)\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.dense1(inputs)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            #x = self.dense2(x)\n            return self.dense3(x)\n        \n    myRegressorModel = myRegressor()\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n                                                     factor=0.001,\n                                                     patience=5, \n                                                     min_lr=1e-10)\n\n    myRegressorModel.compile(optimizer=tf.keras.optimizers.Adam(), \n                             loss=tf.keras.losses.MeanSquaredError(), \n                             metrics=['accuracy'])\n\n    \n    data.dropna(inplace=True)\n    features = data[features]\n    labels = data[label]\n    print('fitting regressor------')\n    history = myRegressorModel.fit(features, labels, epochs=100, callbacks=[early_stopping])\n    \n    return myRegressorModel\n\ndef createCategoricalRegressor(data, features, label):\n    class myCategoricalRegressor(tf.keras.Model):\n        def __init__(self):\n            super().__init__()        \n            self.dense1 = Dense(128, activation='relu')  \n            self.dense2 = Dense(64, activation='relu')         \n            self.dense3 = Dense(len(data[label[0]].unique()), activation='softmax')\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.dense1(inputs)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            #x = self.dense2(x)\n            return self.dense3(x)\n\n\n    myCategoricalRegressorModel = myCategoricalRegressor()\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n                                                     factor=0.001,\n                                                     patience=5, \n                                                     min_lr=1e-10)\n    \n    myCategoricalRegressorModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n                                        loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n                                        metrics=['accuracy'])\n\n    \n    data.dropna(inplace=True)\n    features = data[features].to_numpy()\n    label = data[label].to_numpy()\n    print('fitting categorical regressor------')\n    history = myCategoricalRegressorModel.fit(features, label, epochs= 100, callbacks=[early_stopping])\n    return myCategoricalRegressorModel","metadata":{"execution":{"iopub.status.busy":"2022-07-21T17:08:36.629373Z","iopub.execute_input":"2022-07-21T17:08:36.629763Z","iopub.status.idle":"2022-07-21T17:08:36.683241Z","shell.execute_reply.started":"2022-07-21T17:08:36.629733Z","shell.execute_reply":"2022-07-21T17:08:36.682427Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"features=['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck','Destination', 'HomePlanet', 'Cabin','CryoSleep', 'VIP']\nlabel_column = ['Transported']\ncategorical_columns = ['Destination', 'HomePlanet', 'Cabin']\nboolean_columns = ['CryoSleep', 'VIP']\ndrop_columns=['Name' ,'Hash']\nnumerical_columns=['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\namenityColumns=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\ndef pipeline(df, test=False):\n    df = processCabin(df)\n    df = process_normalize_columns(df, numerical_columns)\n    regressor = createRegressor(df, ['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], ['RoomService'])\n    df = fillAmenityAmount(df, amenityColumns, regressor)\n    df = process_categorical(df, categorical_columns)\n    regressor = createCategoricalRegressor(df, ['Cabin'], ['HomePlanet'])\n    df = fillHomePlanet(df, regressor)\n\n    df.fillna(method='ffill', inplace=True)\n\n    \n    df = proces_boolean(df, boolean_columns)\n    if(not test):\n        df = proces_boolean(df, label_column)\n    for col in numerical_columns:\n        df[col] = pd.to_numeric(df[col])   \n\n    df = process_drop_columns(df, drop_columns) \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-21T17:08:41.091402Z","iopub.execute_input":"2022-07-21T17:08:41.091801Z","iopub.status.idle":"2022-07-21T17:08:41.105768Z","shell.execute_reply.started":"2022-07-21T17:08:41.091771Z","shell.execute_reply":"2022-07-21T17:08:41.104455Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Display dataset","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nBASE_DIR = '/kaggle/input/spaceship-titanic'\ntrain_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'), index_col=0, na_values=\"?\")\ntest_df = pd.read_csv(os.path.join(BASE_DIR, 'test.csv'), index_col=0)\ndisplay(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T17:02:23.223018Z","iopub.execute_input":"2022-07-21T17:02:23.223499Z","iopub.status.idle":"2022-07-21T17:02:23.304852Z","shell.execute_reply.started":"2022-07-21T17:02:23.223431Z","shell.execute_reply":"2022-07-21T17:02:23.303470Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"            HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\nPassengerId                                                              \n0001_01         Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n0002_01          Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n0003_01         Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n0003_02         Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n0004_01          Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n...                ...       ...       ...            ...   ...    ...   \n9276_01         Europa     False    A/98/P    55 Cancri e  41.0   True   \n9278_01          Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n9279_01          Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n9280_01         Europa     False   E/608/S    55 Cancri e  32.0  False   \n9280_02         Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n\n             RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\nPassengerId                                                         \n0001_01              0.0        0.0           0.0     0.0     0.0   \n0002_01            109.0        9.0          25.0   549.0    44.0   \n0003_01             43.0     3576.0           0.0  6715.0    49.0   \n0003_02              0.0     1283.0         371.0  3329.0   193.0   \n0004_01            303.0       70.0         151.0   565.0     2.0   \n...                  ...        ...           ...     ...     ...   \n9276_01              0.0     6819.0           0.0  1643.0    74.0   \n9278_01              0.0        0.0           0.0     0.0     0.0   \n9279_01              0.0        0.0        1872.0     1.0     0.0   \n9280_01              0.0     1049.0           0.0   353.0  3235.0   \n9280_02            126.0     4688.0           0.0     0.0    12.0   \n\n                          Name  Transported  \nPassengerId                                  \n0001_01        Maham Ofracculy        False  \n0002_01           Juanna Vines         True  \n0003_01          Altark Susent        False  \n0003_02           Solam Susent        False  \n0004_01      Willy Santantines         True  \n...                        ...          ...  \n9276_01      Gravior Noxnuther        False  \n9278_01        Kurta Mondalley        False  \n9279_01           Fayey Connon         True  \n9280_01       Celeon Hontichre        False  \n9280_02       Propsh Hontichre         True  \n\n[8693 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0001_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0002_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>0003_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0003_02</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0004_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9276_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/98/P</td>\n      <td>55 Cancri e</td>\n      <td>41.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>6819.0</td>\n      <td>0.0</td>\n      <td>1643.0</td>\n      <td>74.0</td>\n      <td>Gravior Noxnuther</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9278_01</th>\n      <td>Earth</td>\n      <td>True</td>\n      <td>G/1499/S</td>\n      <td>PSO J318.5-22</td>\n      <td>18.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Kurta Mondalley</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9279_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>G/1500/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>26.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1872.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Fayey Connon</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9280_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>55 Cancri e</td>\n      <td>32.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1049.0</td>\n      <td>0.0</td>\n      <td>353.0</td>\n      <td>3235.0</td>\n      <td>Celeon Hontichre</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9280_02</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>44.0</td>\n      <td>False</td>\n      <td>126.0</td>\n      <td>4688.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>Propsh Hontichre</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>8693 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocess Data","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrain_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'), index_col=0)\ntest_df = pd.read_csv(os.path.join(BASE_DIR, 'test.csv'), index_col=0)\n\ntrain_df = pipeline(train_df)\ntest_df = pipeline(test_df, True)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T17:08:51.457794Z","iopub.execute_input":"2022-07-21T17:08:51.458193Z","iopub.status.idle":"2022-07-21T17:09:06.182735Z","shell.execute_reply.started":"2022-07-21T17:08:51.458160Z","shell.execute_reply":"2022-07-21T17:09:06.181528Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"fitting regressor------\nEpoch 1/100\n207/207 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.6536\nEpoch 2/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.6536\nEpoch 3/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.6536\nEpoch 4/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.6536\nEpoch 5/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 6/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 7/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 8/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 9/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 10/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.6536\nEpoch 11/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.6536\nfitting categorical regressor------\nEpoch 1/100\n207/207 [==============================] - 1s 1ms/step - loss: 0.8021 - accuracy: 0.6202\nEpoch 2/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7499\nEpoch 3/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7690\nEpoch 4/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7772\nEpoch 5/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7728\nEpoch 6/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7755\nEpoch 7/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7757\nEpoch 8/100\n207/207 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7746\nEpoch 9/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7725\nEpoch 10/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7731\nEpoch 11/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7734\nEpoch 12/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7737\nEpoch 13/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7726\nEpoch 14/100\n207/207 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7743\nfitting regressor------\nEpoch 1/100\n103/103 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.6532\nEpoch 2/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.6532\nEpoch 3/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 4/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 5/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 6/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 7/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 8/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 9/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 10/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nEpoch 11/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.6532\nfitting categorical regressor------\nEpoch 1/100\n103/103 [==============================] - 1s 1ms/step - loss: 0.9042 - accuracy: 0.5334\nEpoch 2/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.6565\nEpoch 3/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7272\nEpoch 4/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.7446\nEpoch 5/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7510\nEpoch 6/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7550\nEpoch 7/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7586\nEpoch 8/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7601\nEpoch 9/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7601\nEpoch 10/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7607\nEpoch 11/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7586\nEpoch 12/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7568\nEpoch 13/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7550\nEpoch 14/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7623\nEpoch 15/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7583\nEpoch 16/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7583\nEpoch 17/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7583\nEpoch 18/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7592\nEpoch 19/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7577\nEpoch 20/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7589\nEpoch 21/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7556\nEpoch 22/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7601\nEpoch 23/100\n103/103 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7583\nEpoch 24/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7543\n","output_type":"stream"}]},{"cell_type":"code","source":"class myModel(tf.keras.Model):\n    def __init__(self):\n        super().__init__()        \n        self.dense1 = Dense(32, activation='relu')  \n        self.dense2 = Dense(16, activation='relu')         \n        self.dense3 = Dense(1, activation='sigmoid')\n        self.dropout1 = Dropout(0.4)\n        \n    def call(self, inputs, training=False):\n        x = self.dense1(inputs)\n        if(training==False):\n            x = self.dropout1(x, training=training)\n        x = self.dense2(x)        \n        return self.dense3(x)\n    \nmodel = myModel()\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=50)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\ndisplay(train_df.info())\nfeatures = train_df[train_df.columns[:-1]].to_numpy()\nlabels = train_df['Transported'].to_numpy()\n\nhistory = model.fit(features, labels, epochs= 1000, callbacks=[early_stopping])\nprint(history)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T17:12:32.231147Z","iopub.execute_input":"2022-07-21T17:12:32.231571Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 6606 entries, 0001_01 to 9280_02\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   HomePlanet    6606 non-null   int64  \n 1   CryoSleep     6606 non-null   int64  \n 2   Cabin         6606 non-null   int64  \n 3   Destination   6606 non-null   int64  \n 4   Age           6606 non-null   float64\n 5   VIP           6606 non-null   int64  \n 6   RoomService   6606 non-null   float64\n 7   FoodCourt     6606 non-null   float64\n 8   ShoppingMall  6606 non-null   float64\n 9   Spa           6606 non-null   float64\n 10  VRDeck        6606 non-null   float64\n 11  Transported   6606 non-null   int64  \ndtypes: float64(6), int64(6)\nmemory usage: 670.9+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"Epoch 1/1000\n207/207 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.6826\nEpoch 2/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7295\nEpoch 3/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7383\nEpoch 4/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7540\nEpoch 5/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7599\nEpoch 6/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7675\nEpoch 7/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7690\nEpoch 8/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7741\nEpoch 9/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7752\nEpoch 10/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7779\nEpoch 11/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7823\nEpoch 12/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7882\nEpoch 13/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7838\nEpoch 14/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7894\nEpoch 15/1000\n207/207 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.7878\nEpoch 16/1000\n207/207 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.7811\nEpoch 17/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7922\nEpoch 18/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7926\nEpoch 19/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7849\nEpoch 20/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7884\nEpoch 21/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7867\nEpoch 22/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7879\nEpoch 23/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7829\nEpoch 24/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7903\nEpoch 25/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7903\nEpoch 26/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7931\nEpoch 27/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7900\nEpoch 28/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7919\nEpoch 29/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7906\nEpoch 30/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7944\nEpoch 31/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7891\nEpoch 32/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7900\nEpoch 33/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7890\nEpoch 34/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7967\nEpoch 35/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7923\nEpoch 36/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7925\nEpoch 37/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7955\nEpoch 38/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7973\nEpoch 39/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7870\nEpoch 40/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7899\nEpoch 41/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7893\nEpoch 42/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7932\nEpoch 43/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7879\nEpoch 44/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7908\nEpoch 45/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7949\nEpoch 46/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7925\nEpoch 47/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7950\nEpoch 48/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7922\nEpoch 49/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7941\nEpoch 50/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7931\nEpoch 51/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7938\nEpoch 52/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7949\nEpoch 53/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7947\nEpoch 54/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7938\nEpoch 55/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7979\nEpoch 56/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7997\nEpoch 57/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7949\nEpoch 58/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7952\nEpoch 59/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7967\nEpoch 60/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7993\nEpoch 61/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7943\nEpoch 62/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7978\nEpoch 63/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7938\nEpoch 64/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7932\nEpoch 65/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7976\nEpoch 66/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7981\nEpoch 67/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7972\nEpoch 68/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7934\nEpoch 69/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7952\nEpoch 70/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7946\nEpoch 71/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7972\nEpoch 72/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7955\nEpoch 73/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7990\nEpoch 74/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7978\nEpoch 75/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7947\nEpoch 76/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7972\nEpoch 77/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7988\nEpoch 78/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7999\nEpoch 79/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8000\nEpoch 80/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7952\nEpoch 81/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.7979\nEpoch 82/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7967\nEpoch 83/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7934\nEpoch 84/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.7994\nEpoch 85/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.7962\nEpoch 86/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.7962\nEpoch 87/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8012\nEpoch 88/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7955\nEpoch 89/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.7956\nEpoch 90/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7959\nEpoch 91/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8000\nEpoch 92/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8020\nEpoch 93/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7972\nEpoch 94/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8023\nEpoch 95/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8000\nEpoch 96/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.7982\nEpoch 97/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7988\nEpoch 98/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7946\nEpoch 99/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8002\nEpoch 100/1000\n207/207 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8000\nEpoch 101/1000\n153/207 [=====================>........] - ETA: 0s - loss: 0.4043 - accuracy: 0.7966","output_type":"stream"}]},{"cell_type":"code","source":"# pd.crosstab(train_df['Cabin'], train_df['Transported']).plot.bar()\ndf = processCabin(train_df)\npd.crosstab(df['HomePlanet'], df['Cabin']).plot.bar()\npd.crosstab(df['Cabin'], df['HomePlanet']).plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T20:18:23.191580Z","iopub.execute_input":"2022-07-17T20:18:23.192189Z","iopub.status.idle":"2022-07-17T20:18:24.243461Z","shell.execute_reply.started":"2022-07-17T20:18:23.192138Z","shell.execute_reply":"2022-07-17T20:18:24.242483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_df.to_numpy())\npredictions = np.round(predictions)\npredictions = [True if pred == 1 else False for pred in predictions]","metadata":{"execution":{"iopub.status.busy":"2022-07-17T20:05:10.186669Z","iopub.execute_input":"2022-07-17T20:05:10.187090Z","iopub.status.idle":"2022-07-17T20:05:48.979797Z","shell.execute_reply.started":"2022-07-17T20:05:10.187051Z","shell.execute_reply":"2022-07-17T20:05:48.978401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"passenger_id = np.array(test_df.index, ndmin=2)\npreds = np.array(predictions, ndmin=2)\npreds = np.concatenate((passenger_id.T, preds.T), axis=1)\ndf = pd.DataFrame(preds)\ndisplay(df)\n\ndf.to_csv(path_or_buf=\"/kaggle/working/predictions.csv\", header=['PassengerId', 'Transported'], index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T20:05:48.982426Z","iopub.execute_input":"2022-07-17T20:05:48.983062Z","iopub.status.idle":"2022-07-17T20:05:49.012400Z","shell.execute_reply.started":"2022-07-17T20:05:48.983002Z","shell.execute_reply":"2022-07-17T20:05:49.010920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(\"/kaggle/working/predictions.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-17T20:05:04.317474Z","iopub.execute_input":"2022-07-17T20:05:04.318242Z","iopub.status.idle":"2022-07-17T20:05:04.325676Z","shell.execute_reply.started":"2022-07-17T20:05:04.318169Z","shell.execute_reply":"2022-07-17T20:05:04.324207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom matplotlib import pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T10:45:17.379238Z","iopub.execute_input":"2022-07-16T10:45:17.380212Z","iopub.status.idle":"2022-07-16T10:45:17.601444Z","shell.execute_reply.started":"2022-07-16T10:45:17.380176Z","shell.execute_reply":"2022-07-16T10:45:17.600300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fillHomePlanet(df):\n    \n    df1=df[df['HomePlanet'].isna()][['Cabin', 'HomePlanet']]\n    for index, row in df1.iterrows():   \n        \n        features = np.array(df1.loc[index, 'Cabin']) \n        features = features[..., np.newaxis]\n        \n        prediction = myEstimatorModel2.predict(features)\n        print(features , np.argmax(prediction[0]))\n        \n        df.loc[index, 'HomePlanet'] = np.argmax(prediction[0])   \n    \n    return df\n\ndf = process_categorical(train_df, ['Cabin'])\ndf = fillHomePlanet(train_df)\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T19:59:13.983148Z","iopub.execute_input":"2022-07-17T19:59:13.983580Z","iopub.status.idle":"2022-07-17T19:59:14.022666Z","shell.execute_reply.started":"2022-07-17T19:59:13.983541Z","shell.execute_reply":"2022-07-17T19:59:14.021732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame({'key1': [1,2,3,4], 'key2':[5,6,7,8]})\ndf2 = pd.DataFrame({'key1': ['a','b','c', 'd'], 'key2':['e','f', 'g', 'h']})\n\nprint([df1, df2])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-19T08:55:29.820667Z","iopub.execute_input":"2022-07-19T08:55:29.821085Z","iopub.status.idle":"2022-07-19T08:55:29.835975Z","shell.execute_reply.started":"2022-07-19T08:55:29.821052Z","shell.execute_reply":"2022-07-19T08:55:29.834255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pandas_to_numpy(data):\n    '''Convert a pandas DataFrame into a Numpy array'''\n  # Drop empty rows.\n    data = data.dropna(how=\"any\", axis=0)\n  # Separate DataFrame into two Numpy arrays.\n    labels = np.array(data['Transported'])\n    features = data.drop('Transported', axis=1)\n    features = {name:np.array(value) for name, value in features.items()}\n  \n    return features, labels\n\n#@title Visualize Binary Confusion Matrix and Compute Evaluation Metrics Per Subgroup\nCATEGORY  =  \"HomePlanet\" #@param {type:\"string\"}\nSUBGROUP =  1 #@param {type:\"int\"}\n\n# Labels for annotating axes in plot.\nclasses = ['Transported', 'Not Transported']\n\n# Given define subgroup, generate predictions and obtain its corresponding \n# ground truth.\nsubgroup_filter  = train_df.loc[train_df[CATEGORY] == SUBGROUP]\nfeatures, labels = pandas_to_numpy(subgroup_filter)\n\nsubgroup_results = model.evaluate(x=features, y=labels, verbose=0)\ndisplay(subgroup_filter)\nconfusion_matrix = np.array([[subgroup_results[1], subgroup_results[4]], \n                             [subgroup_results[2], subgroup_results[3]]])\n\nsubgroup_performance_metrics = {\n    'ACCURACY': subgroup_results[5],\n    'PRECISION': subgroup_results[6], \n    'RECALL': subgroup_results[7],\n    'AUC': subgroup_results[8]\n}\nperformance_df = pd.DataFrame(subgroup_performance_metrics, index=[SUBGROUP])\npd.options.display.float_format = '{:,.4f}'.format\n\nplot_confusion_matrix(confusion_matrix, classes, SUBGROUP);\nperformance_df","metadata":{"execution":{"iopub.status.busy":"2022-07-21T10:35:54.484283Z","iopub.execute_input":"2022-07-21T10:35:54.484946Z","iopub.status.idle":"2022-07-21T10:35:54.558437Z","shell.execute_reply.started":"2022-07-21T10:35:54.484882Z","shell.execute_reply":"2022-07-21T10:35:54.555900Z"},"trusted":true},"execution_count":57,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_32/2306860489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgroup_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msubgroup_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubgroup_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m confusion_matrix = np.array([[subgroup_results[1], subgroup_results[4]], \n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                **kwargs):\n\u001b[1;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m   1430\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1431\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type dict)."],"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type dict).","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}