{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n\nThe Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n\nWhile rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n\n\n\nTo help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n\nHelp save them and change history!","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.data import Dataset\nimport matplotlib.pyplot as plt\n# pip install seaborn\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, Normalizer\nimport re\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n%config InlineBackend.figure_format = 'retina'\npd.set_option(\"display.precision\", 2)\n\n# For facets\nfrom IPython.core.display import display, HTML\nimport base64\n!pip install facets-overview\nfrom facets_overview.feature_statistics_generator import FeatureStatisticsGenerator\n\nBASE_DIR = '/kaggle/input/spaceship-titanic'\nBASE_DIR_OUTPUT = '/kaggle/working/'\nMODEL_DIR  = '/kaggle/working/model'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-22T07:15:28.045219Z","iopub.execute_input":"2022-07-22T07:15:28.045648Z","iopub.status.idle":"2022-07-22T07:15:38.508472Z","shell.execute_reply.started":"2022-07-22T07:15:28.045609Z","shell.execute_reply":"2022-07-22T07:15:38.507245Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\nRequirement already satisfied: facets-overview in /opt/conda/lib/python3.7/site-packages (1.0.0)\nRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (1.3.5)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (1.21.6)\nRequirement already satisfied: protobuf>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from facets-overview) (3.19.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.22.0->facets-overview) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.22.0->facets-overview) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.22.0->facets-overview) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"#@title Define Function to Visualize Binary Confusion Matrix\ndef plot_confusion_matrix(\n    confusion_matrix, class_names, subgroup, figsize = (8,6)):\n  # We're taking our calculated binary confusion matrix that's already in the \n  # form of an array and turning it into a pandas DataFrame because it's a lot \n  # easier to work with a pandas DataFrame when visualizing a heat map in \n  # Seaborn.\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n\n    rcParams.update({\n      'font.family':'sans-serif',\n      'font.sans-serif':['Liberation Sans'],\n    })\n  \n    sns.set_context(\"notebook\", font_scale=1.25)\n\n    fig = plt.figure(figsize=figsize)\n\n    plt.title('Confusion Matrix for Performance Across ' + subgroup)\n\n    # Combine the instance (numercial value) with its description\n    strings = np.asarray([['True Positives', 'False Negatives'],\n                          ['False Positives', 'True Negatives']])\n    labels = (np.asarray(\n        [\"{0:g}\\n{1}\".format(value, string) for string, value in zip(\n            strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n\n    heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\", \n        linewidths=2.0, cmap=sns.color_palette(\"GnBu_d\"));\n    heatmap.yaxis.set_ticklabels(\n        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n    heatmap.xaxis.set_ticklabels(\n        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n    plt.ylabel('References')\n    plt.xlabel('Predictions')\n    return fig\n\ndef process_drop_columns(df, columns):    \n    new_df = df.drop(columns=columns, axis=1, errors='ignore')\n    return new_df\n\ndef proces_boolean(df, columns):\n    for col in columns:\n        df[col] = [1 if x is True else 0 for x in df[col]]\n    return df\n\ndef process_categorical(df, columns):         \n    le = LabelEncoder()\n    label_object = {}\n    for col in columns:\n        labelencoder = LabelEncoder()\n        labelencoder.fit(df[col])\n        df[col] = labelencoder.fit_transform(df[col])\n        label_object[col] = labelencoder\n    return df\n\ndef create_hash(df):\n    df['Hash'] = df['Surname'].apply(lambda x: hash(tuple(x)))\n    return df\n\ndef processCabin(df):\n    df['Cabin'].replace('\\/\\d+\\/', '/', regex=True, inplace=True)\n    return df\n\ndef processName(df):\n    df['Surname'] = df['Name'].apply(lambda item: item.split(\" \")[1])\n    return df\n\ndef createTrainEvalSets(df):\n    df1 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) < 3]\n    df2 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) >= 3]\n    return (df1, df2)\n# train_df = processCabin(train_df)\n\n#slower\ndef fillAmenityAmount2(df, columns):    \n    for col in df.T.columns:\n        df.T[col].fillna(9, inplace=True)\n    return df  \n    \n    \ndef displayRowsWithNulls(df, columns):\n    display(df[columns][df[columns].isnull().any(axis=1)])\n\ndef process_normalize_columns(df, columns):\n    for col in columns:\n        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n    return df\n\ndef fillAmenityAmount(df, columns, regressor):   \n    df1=df[df[columns].isnull().any(axis=1)][columns]    \n    for index, row in df1.iterrows():              \n        features = df1.loc[index, ~pd.isna(row)]\n        \n        if(len(features) < 4):\n            arr = features.to_numpy()\n            arr = np.append(arr, 0)\n            features = pd.Series(arr).to_numpy()\n        features = np.array(features[..., np.newaxis])     \n        \n        prediction = regressor.predict(features.T)\n        col_name = df1.columns[pd.isna(row)][0]\n        \n        df.loc[index, col_name] = prediction[0]   \n    \n    return df\n\ndef fillHomePlanet(df, regressor):    \n    df1=df[df['HomePlanet'].isna()][['Cabin', 'HomePlanet']]\n    for index, row in df1.iterrows():   \n        \n        features = np.array(df1.loc[index, 'Cabin']) \n        features = features[..., np.newaxis]\n        \n        prediction = regressor.predict(features)\n        \n        df.loc[index, 'HomePlanet'] = np.argmax(prediction[0])   \n    \n    return df\n\ndef displayFacetStatistics(df):\n    fsg = FeatureStatisticsGenerator()\n    dataframes = [\n        {'table': df, 'name': 'trainData'}]\n    spaceshipProto = fsg.ProtoFromDataFrames(dataframes)\n    protostr = base64.b64encode(spaceshipProto.SerializeToString()).decode(\"utf-8\")\n\n\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-overview id=\"elem\"></facets-overview>\n            <script>\n              document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(protostr=protostr)\n    display(HTML(html))\n    \ndef displayFacetsDive(df):\n    SAMPLE_SIZE = 5000 #@param\n    df.dropna(how=\"any\", axis=0, inplace=True)\n    train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n            <script>\n              var data = {jsonstr};\n              document.querySelector(\"#elem\").data = data;\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(jsonstr=train_dive)\n    display(HTML(html))\n    \ndef createRegressor(data, features, label):    \n    class myRegressor(tf.keras.Model):\n        def __init__(self):\n            super().__init__()        \n            self.dense1 = Dense(1, activation='relu')  \n            #self.dense2 = Dense(2, activation='relu')         \n            self.dense3 = Dense(1)\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.dense1(inputs)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            #x = self.dense2(x)\n            return self.dense3(x)\n        \n    myRegressorModel = myRegressor()\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n                                                     factor=0.001,\n                                                     patience=5, \n                                                     min_lr=1e-10)\n\n    myRegressorModel.compile(optimizer=tf.keras.optimizers.Adam(), \n                             loss=tf.keras.losses.MeanSquaredError(), \n                             metrics=['accuracy'])\n\n    \n    data.dropna(inplace=True)\n    features = data[features]\n    labels = data[label]\n    print('fitting regressor------')\n    history = myRegressorModel.fit(features, labels, epochs=100, callbacks=[early_stopping])\n    \n    return myRegressorModel\n\ndef createCategoricalRegressor(data, features, label):\n    class myCategoricalRegressor(tf.keras.Model):\n        def __init__(self):\n            super().__init__()        \n            self.dense1 = Dense(128, activation='relu')  \n            self.dense2 = Dense(64, activation='relu')         \n            self.dense3 = Dense(len(data[label[0]].unique()), activation='softmax')\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.dense1(inputs)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            #x = self.dense2(x)\n            return self.dense3(x)\n\n\n    myCategoricalRegressorModel = myCategoricalRegressor()\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n                                                     factor=0.001,\n                                                     patience=5, \n                                                     min_lr=1e-10)\n    \n    myCategoricalRegressorModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n                                        loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n                                        metrics=['accuracy'])\n\n    \n    data.dropna(inplace=True)\n    features = data[features].to_numpy()\n    label = data[label].to_numpy()\n    print('fitting categorical regressor------')\n    history = myCategoricalRegressorModel.fit(features, label, epochs= 100, callbacks=[early_stopping])\n    return myCategoricalRegressorModel\n\ndef train_model(data):\n    class myModel(tf.keras.Model):\n        def __init__(self):\n            super().__init__()        \n            self.dense1 = Dense(32, activation='relu')  \n            self.dense2 = Dense(16, activation='relu')         \n            self.dense3 = Dense(1, activation='sigmoid')\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.dense1(inputs)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            x = self.dense2(x)        \n            return self.dense3(x)\n\n    model = myModel()\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n    display(data.info())\n    features = data[data.columns[:-1]].to_numpy()\n    labels = data['Transported'].to_numpy()\n\n    history = model.fit(features, labels, epochs= 200, callbacks=[early_stopping])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:31:38.169821Z","iopub.execute_input":"2022-07-22T07:31:38.170237Z","iopub.status.idle":"2022-07-22T07:31:38.220311Z","shell.execute_reply.started":"2022-07-22T07:31:38.170203Z","shell.execute_reply":"2022-07-22T07:31:38.219087Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nBASE_DIR = '/kaggle/input/spaceship-titanic'\ntrain_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'), index_col=0)\ntest_df = pd.read_csv(os.path.join(BASE_DIR, 'test.csv'), index_col=0)\ndisplay(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:15:40.192814Z","iopub.execute_input":"2022-07-22T07:15:40.193235Z","iopub.status.idle":"2022-07-22T07:15:40.265470Z","shell.execute_reply.started":"2022-07-22T07:15:40.193199Z","shell.execute_reply":"2022-07-22T07:15:40.264440Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"            HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\nPassengerId                                                              \n0001_01         Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n0002_01          Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n0003_01         Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n0003_02         Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n0004_01          Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n...                ...       ...       ...            ...   ...    ...   \n9276_01         Europa     False    A/98/P    55 Cancri e  41.0   True   \n9278_01          Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n9279_01          Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n9280_01         Europa     False   E/608/S    55 Cancri e  32.0  False   \n9280_02         Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n\n             RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\nPassengerId                                                         \n0001_01              0.0        0.0           0.0     0.0     0.0   \n0002_01            109.0        9.0          25.0   549.0    44.0   \n0003_01             43.0     3576.0           0.0  6715.0    49.0   \n0003_02              0.0     1283.0         371.0  3329.0   193.0   \n0004_01            303.0       70.0         151.0   565.0     2.0   \n...                  ...        ...           ...     ...     ...   \n9276_01              0.0     6819.0           0.0  1643.0    74.0   \n9278_01              0.0        0.0           0.0     0.0     0.0   \n9279_01              0.0        0.0        1872.0     1.0     0.0   \n9280_01              0.0     1049.0           0.0   353.0  3235.0   \n9280_02            126.0     4688.0           0.0     0.0    12.0   \n\n                          Name  Transported  \nPassengerId                                  \n0001_01        Maham Ofracculy        False  \n0002_01           Juanna Vines         True  \n0003_01          Altark Susent        False  \n0003_02           Solam Susent        False  \n0004_01      Willy Santantines         True  \n...                        ...          ...  \n9276_01      Gravior Noxnuther        False  \n9278_01        Kurta Mondalley        False  \n9279_01           Fayey Connon         True  \n9280_01       Celeon Hontichre        False  \n9280_02       Propsh Hontichre         True  \n\n[8693 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0001_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0002_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>0003_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0003_02</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0004_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9276_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/98/P</td>\n      <td>55 Cancri e</td>\n      <td>41.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>6819.0</td>\n      <td>0.0</td>\n      <td>1643.0</td>\n      <td>74.0</td>\n      <td>Gravior Noxnuther</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9278_01</th>\n      <td>Earth</td>\n      <td>True</td>\n      <td>G/1499/S</td>\n      <td>PSO J318.5-22</td>\n      <td>18.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Kurta Mondalley</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9279_01</th>\n      <td>Earth</td>\n      <td>False</td>\n      <td>G/1500/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>26.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1872.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Fayey Connon</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9280_01</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>55 Cancri e</td>\n      <td>32.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1049.0</td>\n      <td>0.0</td>\n      <td>353.0</td>\n      <td>3235.0</td>\n      <td>Celeon Hontichre</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9280_02</th>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>44.0</td>\n      <td>False</td>\n      <td>126.0</td>\n      <td>4688.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>Propsh Hontichre</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>8693 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"features=['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck','Destination', 'HomePlanet', 'Cabin','CryoSleep', 'VIP']\nlabel_column = ['Transported']\ncategorical_columns = ['Destination', 'HomePlanet', 'Cabin']\nboolean_columns = ['CryoSleep', 'VIP']\ndrop_columns=['Name' ,'Hash']\nnumerical_columns=['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\namenityColumns=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\ndef run_data_preprocess_pipeline(df, out, test=False):\n    if(not test):\n        filename = 'train.csv'\n    else:\n        filename = 'test.csv'\n        \n    df = load_data(BASE_DIR, filename)    \n    \n    df = processCabin(df)\n    df = process_normalize_columns(df, numerical_columns)\n    regressor = createRegressor(df, ['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], ['RoomService'])\n    df = fillAmenityAmount(df, amenityColumns, regressor)\n    df = process_categorical(df, categorical_columns)\n    regressor = createCategoricalRegressor(df, ['Cabin'], ['HomePlanet'])\n    df = fillHomePlanet(df, regressor)\n\n    df.fillna(method='ffill', inplace=True)\n\n    \n    df = proces_boolean(df, boolean_columns)\n    if(not test):\n        df = proces_boolean(df, label_column)\n    for col in numerical_columns:\n        df[col] = pd.to_numeric(df[col])   \n\n    df = process_drop_columns(df, drop_columns) \n    df.to_csv(os.path.join(BASE_DIR_OUTPUT, out))\n    return df\n    \ndef load_data(BASE_DIR, filename):\n    data = pd.read_csv(os.path.join(BASE_DIR, filename), index_col=0, sep=',')    \n    return data\n    \ndef pipeline(df, out, test=False):\n    if(not os.path.exists(out)):\n        df = run_data_preprocess_pipeline(df, out, test)\n    else:\n        df = load_data(BASE_DIR_OUTPUT, out)  \n    \n    display(df)\n    if(not test):\n        model = train_model(df)\n        model.save(os.path.join(BASE_DIR_OUTPUT, 'spaceship_model'), save_format='tf')\n        return model\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:38:32.908669Z","iopub.execute_input":"2022-07-22T07:38:32.909132Z","iopub.status.idle":"2022-07-22T07:38:32.925486Z","shell.execute_reply.started":"2022-07-22T07:38:32.909092Z","shell.execute_reply":"2022-07-22T07:38:32.924223Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n\npipeline(train_df, 'train.csv')\npipeline(test_df, 'test.csv', True)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:38:38.605501Z","iopub.execute_input":"2022-07-22T07:38:38.606908Z","iopub.status.idle":"2022-07-22T07:38:53.983937Z","shell.execute_reply.started":"2022-07-22T07:38:38.606844Z","shell.execute_reply":"2022-07-22T07:38:53.982768Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"             HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  \\\nPassengerId                                                         \n0001_01               1          0      2            2  0.49    0   \n0002_01               0          0     11            2  0.30    0   \n0003_01               1          0      1            2  0.73    1   \n0003_02               1          0      1            2  0.42    0   \n0004_01               0          0     11            2  0.20    0   \n...                 ...        ...    ...          ...   ...  ...   \n9276_01               1          0      0            0  0.52    1   \n9278_01               0          1     13            1  0.23    0   \n9279_01               0          0     13            2  0.33    0   \n9280_01               1          0      9            0  0.41    0   \n9280_02               1          0      9            2  0.56    0   \n\n             RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  \\\nPassengerId                                                             \n0001_01         0.00e+00   0.00e+00      0.00e+00  0.00e+00  0.00e+00   \n0002_01         7.61e-03   3.02e-04      1.06e-03  2.45e-02  1.82e-03   \n0003_01         3.00e-03   1.20e-01      0.00e+00  3.00e-01  2.03e-03   \n0003_02         0.00e+00   4.30e-02      1.58e-02  1.49e-01  8.00e-03   \n0004_01         2.11e-02   2.35e-03      6.43e-03  2.52e-02  8.29e-05   \n...                  ...        ...           ...       ...       ...   \n9276_01         0.00e+00   2.29e-01      0.00e+00  7.33e-02  3.07e-03   \n9278_01         0.00e+00   0.00e+00      0.00e+00  0.00e+00  0.00e+00   \n9279_01         0.00e+00   0.00e+00      7.97e-02  4.46e-05  0.00e+00   \n9280_01         0.00e+00   3.52e-02      0.00e+00  1.58e-02  1.34e-01   \n9280_02         8.79e-03   1.57e-01      0.00e+00  0.00e+00  4.97e-04   \n\n             Transported  \nPassengerId               \n0001_01                0  \n0002_01                1  \n0003_01                0  \n0003_02                0  \n0004_01                1  \n...                  ...  \n9276_01                0  \n9278_01                0  \n9279_01                1  \n9280_01                0  \n9280_02                1  \n\n[6606 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Transported</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0001_01</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.49</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0002_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>7.61e-03</td>\n      <td>3.02e-04</td>\n      <td>1.06e-03</td>\n      <td>2.45e-02</td>\n      <td>1.82e-03</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0003_01</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.73</td>\n      <td>1</td>\n      <td>3.00e-03</td>\n      <td>1.20e-01</td>\n      <td>0.00e+00</td>\n      <td>3.00e-01</td>\n      <td>2.03e-03</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0003_02</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.42</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>4.30e-02</td>\n      <td>1.58e-02</td>\n      <td>1.49e-01</td>\n      <td>8.00e-03</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0004_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.20</td>\n      <td>0</td>\n      <td>2.11e-02</td>\n      <td>2.35e-03</td>\n      <td>6.43e-03</td>\n      <td>2.52e-02</td>\n      <td>8.29e-05</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9276_01</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.52</td>\n      <td>1</td>\n      <td>0.00e+00</td>\n      <td>2.29e-01</td>\n      <td>0.00e+00</td>\n      <td>7.33e-02</td>\n      <td>3.07e-03</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9278_01</th>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0.23</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9279_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>2</td>\n      <td>0.33</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>7.97e-02</td>\n      <td>4.46e-05</td>\n      <td>0.00e+00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9280_01</th>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0.41</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>3.52e-02</td>\n      <td>0.00e+00</td>\n      <td>1.58e-02</td>\n      <td>1.34e-01</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9280_02</th>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.56</td>\n      <td>0</td>\n      <td>8.79e-03</td>\n      <td>1.57e-01</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>4.97e-04</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6606 rows × 12 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 6606 entries, 0001_01 to 9280_02\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   HomePlanet    6606 non-null   int64  \n 1   CryoSleep     6606 non-null   int64  \n 2   Cabin         6606 non-null   int64  \n 3   Destination   6606 non-null   int64  \n 4   Age           6606 non-null   float64\n 5   VIP           6606 non-null   int64  \n 6   RoomService   6606 non-null   float64\n 7   FoodCourt     6606 non-null   float64\n 8   ShoppingMall  6606 non-null   float64\n 9   Spa           6606 non-null   float64\n 10  VRDeck        6606 non-null   float64\n 11  Transported   6606 non-null   int64  \ndtypes: float64(6), int64(6)\nmemory usage: 670.9+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"Epoch 1/200\n207/207 [==============================] - 1s 2ms/step - loss: 0.7503 - accuracy: 0.6011\nEpoch 2/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7262\nEpoch 3/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7408\nEpoch 4/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7469\nEpoch 5/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7560\nEpoch 6/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7642\nEpoch 7/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7670\nEpoch 8/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7696\nEpoch 9/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7710\nEpoch 10/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7769\nEpoch 11/200\n207/207 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7785\nEpoch 12/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7828\nEpoch 13/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7808\nEpoch 14/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7816\nEpoch 15/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7837\nEpoch 16/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7832\nEpoch 17/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7820\nEpoch 18/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7882\nEpoch 19/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7844\nEpoch 20/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7869\nEpoch 21/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7866\nEpoch 22/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7867\nEpoch 23/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7875\nEpoch 24/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7873\nEpoch 25/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7893\nEpoch 26/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7811\nEpoch 27/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7958\nEpoch 28/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7852\nEpoch 29/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7894\nEpoch 30/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7916\nEpoch 31/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7940\nEpoch 32/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7908\nEpoch 33/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7947\nEpoch 34/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7894\nEpoch 35/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7925\nEpoch 36/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.7978\nEpoch 37/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7938\nEpoch 38/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.7964\nEpoch 39/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7878\nEpoch 40/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.7956\nEpoch 41/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.7925\nEpoch 42/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.7943\nEpoch 43/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.7934\nEpoch 44/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.7934\nEpoch 45/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.7916\nEpoch 46/200\n207/207 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.7949\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             HomePlanet  CryoSleep  Cabin  Destination   Age  VIP  \\\nPassengerId                                                         \n0013_01               0          1     13            2  0.34    0   \n0018_01               0          0     11            2  0.24    0   \n0019_01               1          1      5            0  0.39    0   \n0021_01               1          0      5            2  0.48    0   \n0023_01               0          0     11            2  0.25    0   \n...                 ...        ...    ...          ...   ...  ...   \n9263_01               0          1     13            2  0.54    0   \n9265_01               2          0      7            2  0.54    0   \n9266_01               0          0     11            2  0.51    0   \n9266_02               0          1     13            2  0.43    0   \n9277_01               0          1     13            1  0.54    0   \n\n             RoomService  FoodCourt  ShoppingMall       Spa  VRDeck  \nPassengerId                                                          \n0013_01         0.00e+00   0.00e+00          0.00  0.00e+00    0.00  \n0018_01         0.00e+00   3.56e-04          0.00  1.42e-01    0.00  \n0019_01         0.00e+00   0.00e+00          0.00  0.00e+00    0.00  \n0021_01         0.00e+00   2.63e-01          0.00  9.12e-03    0.03  \n0023_01         8.65e-04   0.00e+00          0.08  0.00e+00    0.00  \n...                  ...        ...           ...       ...     ...  \n9263_01         0.00e+00   0.00e+00          0.00  0.00e+00    0.00  \n9265_01         4.06e-03   0.00e+00          0.46  0.00e+00    0.00  \n9266_01         0.00e+00   3.42e-02          0.00  1.51e-04    0.00  \n9266_02         0.00e+00   0.00e+00          0.00  0.00e+00    0.00  \n9277_01         0.00e+00   0.00e+00          0.00  0.00e+00    0.00  \n\n[3281 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0013_01</th>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>0.34</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>0018_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.24</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>3.56e-04</td>\n      <td>0.00</td>\n      <td>1.42e-01</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>0019_01</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.39</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>0021_01</th>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.48</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>2.63e-01</td>\n      <td>0.00</td>\n      <td>9.12e-03</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>0023_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.25</td>\n      <td>0</td>\n      <td>8.65e-04</td>\n      <td>0.00e+00</td>\n      <td>0.08</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9263_01</th>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>0.54</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>9265_01</th>\n      <td>2</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0.54</td>\n      <td>0</td>\n      <td>4.06e-03</td>\n      <td>0.00e+00</td>\n      <td>0.46</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>9266_01</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0.51</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>3.42e-02</td>\n      <td>0.00</td>\n      <td>1.51e-04</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>9266_02</th>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>0.43</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>9277_01</th>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0.54</td>\n      <td>0</td>\n      <td>0.00e+00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n      <td>0.00e+00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>3281 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions = model.predict(test_df.to_numpy())\npredictions = np.round(predictions)\npredictions = [True if pred == 1 else False for pred in predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"passenger_id = np.array(test_df.index, ndmin=2)\npreds = np.array(predictions, ndmin=2)\npreds = np.concatenate((passenger_id.T, preds.T), axis=1)\ndf = pd.DataFrame(preds)\ndisplay(df)\n\ndf.to_csv(path_or_buf=\"/kaggle/working/predictions.csv\", header=['PassengerId', 'Transported'], index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove(\"/kaggle/working/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:27:42.479661Z","iopub.execute_input":"2022-07-22T07:27:42.480774Z","iopub.status.idle":"2022-07-22T07:27:42.485547Z","shell.execute_reply.started":"2022-07-22T07:27:42.480727Z","shell.execute_reply":"2022-07-22T07:27:42.484365Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom matplotlib import pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pandas_to_numpy(data):\n    '''Convert a pandas DataFrame into a Numpy array'''\n  # Drop empty rows.\n    data = data.dropna(how=\"any\", axis=0)\n  # Separate DataFrame into two Numpy arrays.\n    labels = np.array(data['Transported'])\n    features = data.drop('Transported', axis=1)\n    features = {name:np.array(value) for name, value in features.items()}\n  \n    return features, labels\n\n#@title Visualize Binary Confusion Matrix and Compute Evaluation Metrics Per Subgroup\nCATEGORY  =  \"HomePlanet\" #@param {type:\"string\"}\nSUBGROUP =  1 #@param {type:\"int\"}\n\n# Labels for annotating axes in plot.\nclasses = ['Transported', 'Not Transported']\n\n# Given define subgroup, generate predictions and obtain its corresponding \n# ground truth.\nsubgroup_filter  = train_df.loc[train_df[CATEGORY] == SUBGROUP]\nfeatures, labels = pandas_to_numpy(subgroup_filter)\n\nsubgroup_results = model.evaluate(x=features, y=labels, verbose=0)\ndisplay(subgroup_filter)\nconfusion_matrix = np.array([[subgroup_results[1], subgroup_results[4]], \n                             [subgroup_results[2], subgroup_results[3]]])\n\nsubgroup_performance_metrics = {\n    'ACCURACY': subgroup_results[5],\n    'PRECISION': subgroup_results[6], \n    'RECALL': subgroup_results[7],\n    'AUC': subgroup_results[8]\n}\nperformance_df = pd.DataFrame(subgroup_performance_metrics, index=[SUBGROUP])\npd.options.display.float_format = '{:,.4f}'.format\n\nplot_confusion_matrix(confusion_matrix, classes, SUBGROUP);\nperformance_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}