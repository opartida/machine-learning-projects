{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n\nThe Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n\nWhile rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n\n\n\nTo help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n\nHelp save them and change history!","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.data import Dataset\nfrom tensorflow import feature_column\nimport matplotlib.pyplot as plt\n# pip install seaborn\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, Normalizer\nimport re\nimport math\nimport copy\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n%config InlineBackend.figure_format = 'retina'\npd.set_option(\"display.precision\", 2)\nBASE_DIR = '/kaggle/input/spaceship-titanic'\nBASE_DIR_OUTPUT = '/kaggle/working/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-23T10:15:02.113983Z","iopub.execute_input":"2022-07-23T10:15:02.114382Z","iopub.status.idle":"2022-07-23T10:15:02.144460Z","shell.execute_reply.started":"2022-07-23T10:15:02.114352Z","shell.execute_reply":"2022-07-23T10:15:02.143343Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"/kaggle/input/spaceship-titanic/sample_submission.csv\n/kaggle/input/spaceship-titanic/train.csv\n/kaggle/input/spaceship-titanic/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# For facets\nfrom IPython.core.display import display, HTML\nimport base64\n!pip install facets-overview\nfrom facets_overview.feature_statistics_generator import FeatureStatisticsGenerator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"    \nALL_COLUMNS = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck','Destination', 'HomePlanet', 'Cabin','CryoSleep', 'Transported']\nLABEL_COLUMN = ['Transported']\nCATEGORICAL_COLUMNS = ['Destination', 'HomePlanet', 'Cabin']\nBOOLEAN_COLUMNS = ['CryoSleep']\nDROP_COLUMNS = ['Name' ,'Hash', 'VIP']\nNUMERICAL_COLUMNS = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\nAMENITY_COLUMNS = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']    \n\n\ndef plot_confusion_matrix(\n    confusion_matrix, class_names, subgroup, figsize = (8,6)):\n \n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n\n    rcParams.update({\n      'font.family':'sans-serif',\n      'font.sans-serif':['Liberation Sans'],\n    })\n  \n    sns.set_context(\"notebook\", font_scale=1.25)\n\n    fig = plt.figure(figsize=figsize)\n\n    plt.title('Confusion Matrix for Performance Across ' + subgroup)\n\n    # Combine the instance (numercial value) with its description\n    strings = np.asarray([['True Positives', 'False Negatives'],\n                          ['False Positives', 'True Negatives']])\n    labels = (np.asarray(\n        [\"{0:g}\\n{1}\".format(value, string) for string, value in zip(\n            strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n\n    heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\", \n        linewidths=2.0, cmap=sns.color_palette(\"GnBu_d\"));\n    heatmap.yaxis.set_ticklabels(\n        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n    heatmap.xaxis.set_ticklabels(\n        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n    plt.ylabel('References')\n    plt.xlabel('Predictions')\n    return fig\n\ndef createTrainEvalSets(df):\n    df1 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) < 3]\n    df2 = df[np.mod(np.abs(df['Name'].apply(lambda item: hash(item.split(\" \")[1]))), 4) >= 3]\n    return (df1, df2)\n    \ndef displayRowsWithNulls(df, columns):\n    display(df[columns][df[columns].isnull().any(axis=1)])\n\ndef displayFacetStatistics(df):\n    fsg = FeatureStatisticsGenerator()\n    dataframes = [\n        {'table': df, 'name': 'trainData'}]\n    spaceshipProto = fsg.ProtoFromDataFrames(dataframes)\n    protostr = base64.b64encode(spaceshipProto.SerializeToString()).decode(\"utf-8\")\n\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-overview id=\"elem\"></facets-overview>\n            <script>\n              document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(protostr=protostr)\n    display(HTML(html))\n    \ndef displayFacetsDive(df):\n    SAMPLE_SIZE = len(df.index) - 1\n    df.dropna(how=\"any\", axis=0, inplace=True)\n    train_dive = df.to_json(orient='records')\n    HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n            <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n            <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n            <script>\n              var data = {jsonstr};\n              document.querySelector(\"#elem\").data = data;\n            </script>\"\"\"\n    html = HTML_TEMPLATE.format(jsonstr=train_dive)\n    display(HTML(html))\n\ndef train_model(train_ds, feature_layer):\n    class myModel(tf.keras.Model):\n        def __init__(self):\n            super().__init__()\n            self.feature_layer = feature_layer\n            self.dense1 = Dense(32, activation='relu')  \n            self.dense2 = Dense(16, activation='relu')         \n            self.dense3 = Dense(1, activation='sigmoid')\n            self.dropout1 = Dropout(0.4)\n\n        def call(self, inputs, training=False):\n            x = self.feature_layer(inputs)\n            x = self.dense1(x)\n            if(training==False):\n                x = self.dropout1(x, training=training)\n            x = self.dense2(x)        \n            return self.dense3(x)\n\n    model = myModel()\n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), \n                  loss=tf.keras.losses.BinaryCrossentropy(), \n                  metrics=['accuracy'])\n\n    history = model.fit(train_ds, epochs= 100, callbacks=[early_stopping])\n    model.save(os.path.join(BASE_DIR_OUTPUT, 'spaceship_model'), save_format='tf')\n\ndef make_predictions(ds):\n    \n    model = load_model(os.path.join(BASE_DIR_OUTPUT, 'spaceship_model'))\n    predictions = model.predict(ds)\n    predictions = np.round(predictions)\n    predictions = [True if pred == 1 else False for pred in predictions]\n    \n    passenger_id = np.concatenate(np.array([x['PassengerId'].numpy() for x in ds]), axis=0)\n    passenger_id = np.array([x.decode(\"utf-8\") for x in passenger_id])\n    passenger_id = np.expand_dims(passenger_id, axis=1)\n    preds = np.array(predictions, ndmin=2)\n    \n    preds = np.concatenate((passenger_id, preds.T), axis=1)\n    df = pd.DataFrame(preds)\n    predictions_file = os.path.join(BASE_DIR_OUTPUT, 'predictions.csv')\n    \n    if(os.path.exists(predictions_file)):\n        os.remove(predictions_file)\n            \n    df.to_csv(path_or_buf=predictions_file, header=['PassengerId', 'Transported'], index=False)\n        \ndef df_to_dataset(dataframe, shuffle=True, batch_size=32, test=False):\n    dataframe = dataframe.copy()\n    \n    if(not test):\n        labels = dataframe.pop(label_column[0])\n        ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    else:\n        ds = tf.data.Dataset.from_tensor_slices((dict(dataframe)))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dataframe))\n    ds = ds.batch(batch_size)\n    return ds     \n\ndef fill_na(df):\n    values = {col: df[col].value_counts().idxmax() for col in df.columns}\n    df.fillna(values, inplace=True)\n    return df\n  \n","metadata":{"execution":{"iopub.status.busy":"2022-07-23T12:49:08.637465Z","iopub.execute_input":"2022-07-23T12:49:08.637894Z","iopub.status.idle":"2022-07-23T12:49:08.681076Z","shell.execute_reply.started":"2022-07-23T12:49:08.637861Z","shell.execute_reply":"2022-07-23T12:49:08.680033Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"# with tf.dataset\nbatch_size = 10\ntrain_df = fill_na(train_df)\ntest_df = fill_na(test_df)\ntrain_ds = df_to_dataset(train_df, batch_size=batch_size)\ntest_ds = df_to_dataset(test_df, test=True)\nexample_batch = next(iter(train_ds))[0]\n\ndef demo(feature_column):\n    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n    print(feature_layer(example_batch).numpy())\n    return feature_layer(example_batch).numpy()\n\n\nfeature_columns = []\n\n# numeric cols\nfor col in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n    feature_columns.append(feature_column.numeric_column(col))\n\n# bucketized cols\nage = feature_column.numeric_column('Age')\nage_buckets = feature_column.bucketized_column(age, boundaries=[0, 13, 20, 40, 60])\nfeature_columns.append(age_buckets)\n\n# indicator_columns\nindicator_column_names = ['HomePlanet', 'Destination']\nfor col_name in indicator_column_names:\n    categorical_column = feature_column.categorical_column_with_vocabulary_list(\n        col_name, train_df[col_name].unique())\n    indicator_column = feature_column.indicator_column(categorical_column)\n    feature_columns.append(indicator_column)\n    \n# embedding columns\ncabin = feature_column.categorical_column_with_vocabulary_list(\n    'Cabin', train_df.Cabin.unique())\ncabin_embedding = feature_column.embedding_column(cabin, dimension=8)\nfeature_columns.append(cabin_embedding)\n\nfeature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n\ntrain_model(train_ds, feature_layer)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T12:52:05.354425Z","iopub.execute_input":"2022-07-23T12:52:05.355083Z","iopub.status.idle":"2022-07-23T12:57:02.881111Z","shell.execute_reply.started":"2022-07-23T12:52:05.355048Z","shell.execute_reply":"2022-07-23T12:57:02.879887Z"},"trusted":true},"execution_count":185,"outputs":[{"name":"stdout","text":"Epoch 1/100\n870/870 [==============================] - 4s 4ms/step - loss: 5.5201 - accuracy: 0.7328\nEpoch 2/100\n870/870 [==============================] - 3s 3ms/step - loss: 2.1200 - accuracy: 0.7608\nEpoch 3/100\n870/870 [==============================] - 3s 3ms/step - loss: 1.8584 - accuracy: 0.7598\nEpoch 4/100\n870/870 [==============================] - 3s 3ms/step - loss: 1.5036 - accuracy: 0.7782\nEpoch 5/100\n870/870 [==============================] - 3s 3ms/step - loss: 1.3538 - accuracy: 0.7870\nEpoch 6/100\n870/870 [==============================] - 3s 3ms/step - loss: 1.2006 - accuracy: 0.8075\nEpoch 7/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.8248 - accuracy: 0.8215\nEpoch 8/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.6931 - accuracy: 0.8340\nEpoch 9/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.5575 - accuracy: 0.8427\nEpoch 10/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3972 - accuracy: 0.8514\nEpoch 11/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3653 - accuracy: 0.8597\nEpoch 12/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3483 - accuracy: 0.8662\nEpoch 13/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3576 - accuracy: 0.8659\nEpoch 14/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3179 - accuracy: 0.8686\nEpoch 15/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3220 - accuracy: 0.8742\nEpoch 16/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.3029 - accuracy: 0.8727\nEpoch 17/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2908 - accuracy: 0.8727\nEpoch 18/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2809 - accuracy: 0.8769\nEpoch 19/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2653 - accuracy: 0.8862\nEpoch 20/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2451 - accuracy: 0.8932\nEpoch 21/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2403 - accuracy: 0.8949\nEpoch 22/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2291 - accuracy: 0.9066\nEpoch 23/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2226 - accuracy: 0.9107\nEpoch 24/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9211\nEpoch 25/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.2147 - accuracy: 0.9071\nEpoch 26/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1874 - accuracy: 0.9212\nEpoch 27/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1807 - accuracy: 0.9307\nEpoch 28/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1597 - accuracy: 0.9396\nEpoch 29/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1422 - accuracy: 0.9447\nEpoch 30/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1400 - accuracy: 0.9435\nEpoch 31/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1345 - accuracy: 0.9437\nEpoch 32/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9483\nEpoch 33/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1293 - accuracy: 0.9482\nEpoch 34/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1351 - accuracy: 0.9496\nEpoch 35/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1169 - accuracy: 0.9543\nEpoch 36/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1146 - accuracy: 0.9540\nEpoch 37/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1069 - accuracy: 0.9573\nEpoch 38/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1061 - accuracy: 0.9576\nEpoch 39/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1033 - accuracy: 0.9573\nEpoch 40/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0997 - accuracy: 0.9613\nEpoch 41/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0953 - accuracy: 0.9622\nEpoch 42/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.1026 - accuracy: 0.9608\nEpoch 43/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.9656\nEpoch 44/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0873 - accuracy: 0.9661\nEpoch 45/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0859 - accuracy: 0.9664\nEpoch 46/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.9638\nEpoch 47/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.9694\nEpoch 48/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0755 - accuracy: 0.9707\nEpoch 49/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0725 - accuracy: 0.9709\nEpoch 50/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0697 - accuracy: 0.9734\nEpoch 51/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.9718\nEpoch 52/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0747 - accuracy: 0.9722\nEpoch 53/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0655 - accuracy: 0.9749\nEpoch 54/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0627 - accuracy: 0.9737\nEpoch 55/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0755 - accuracy: 0.9737\nEpoch 56/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0613 - accuracy: 0.9741\nEpoch 57/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0624 - accuracy: 0.9771\nEpoch 58/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0684 - accuracy: 0.9740\nEpoch 59/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0609 - accuracy: 0.9793\nEpoch 60/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0559 - accuracy: 0.9778\nEpoch 61/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0594 - accuracy: 0.9772\nEpoch 62/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0524 - accuracy: 0.9796\nEpoch 63/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0565 - accuracy: 0.9780\nEpoch 64/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0614 - accuracy: 0.9781\nEpoch 65/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0524 - accuracy: 0.9784\nEpoch 66/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0489 - accuracy: 0.9804\nEpoch 67/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0549 - accuracy: 0.9791\nEpoch 68/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0480 - accuracy: 0.9806\nEpoch 69/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0525 - accuracy: 0.9781\nEpoch 70/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0543 - accuracy: 0.9765\nEpoch 71/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0465 - accuracy: 0.9809\nEpoch 72/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0442 - accuracy: 0.9826\nEpoch 73/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0454 - accuracy: 0.9815\nEpoch 74/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9825\nEpoch 75/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0472 - accuracy: 0.9821\nEpoch 76/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0487 - accuracy: 0.9815\nEpoch 77/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0526 - accuracy: 0.9804\nEpoch 78/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0422 - accuracy: 0.9822\nEpoch 79/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0435 - accuracy: 0.9831\nEpoch 80/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0419 - accuracy: 0.9838\nEpoch 81/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0399 - accuracy: 0.9833\nEpoch 82/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0447 - accuracy: 0.9831\nEpoch 83/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0419 - accuracy: 0.9826\nEpoch 84/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0445 - accuracy: 0.9830\nEpoch 85/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0503 - accuracy: 0.9844\nEpoch 86/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9834\nEpoch 87/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0423 - accuracy: 0.9830\nEpoch 88/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0417 - accuracy: 0.9826\nEpoch 89/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0379 - accuracy: 0.9831\nEpoch 90/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0439 - accuracy: 0.9822\nEpoch 91/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0379 - accuracy: 0.9825\nEpoch 92/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0364 - accuracy: 0.9842\nEpoch 93/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0416 - accuracy: 0.9816\nEpoch 94/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0363 - accuracy: 0.9850\nEpoch 95/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0380 - accuracy: 0.9833\nEpoch 96/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0370 - accuracy: 0.9849\nEpoch 97/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0353 - accuracy: 0.9859\nEpoch 98/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0351 - accuracy: 0.9862\nEpoch 99/100\n870/870 [==============================] - 3s 4ms/step - loss: 0.0420 - accuracy: 0.9840\nEpoch 100/100\n870/870 [==============================] - 3s 3ms/step - loss: 0.0411 - accuracy: 0.9849\n","output_type":"stream"}]},{"cell_type":"code","source":"make_predictions(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T12:59:28.436104Z","iopub.execute_input":"2022-07-23T12:59:28.436993Z","iopub.status.idle":"2022-07-23T12:59:30.090980Z","shell.execute_reply.started":"2022-07-23T12:59:28.436924Z","shell.execute_reply":"2022-07-23T12:59:30.090004Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stdout","text":"(4277, 1)\n(1, 4277)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nBASE_DIR = '/kaggle/input/spaceship-titanic'\ntrain_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'), index_col=0)\ntest_df = pd.read_csv(os.path.join(BASE_DIR, 'test.csv'), index_col=0)\ntrain_df = train_df.reset_index()\ntest_df = test_df.reset_index()\ndisplay(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:33:00.876883Z","iopub.execute_input":"2022-07-23T10:33:00.877303Z","iopub.status.idle":"2022-07-23T10:33:00.961091Z","shell.execute_reply.started":"2022-07-23T10:33:00.877272Z","shell.execute_reply":"2022-07-23T10:33:00.959727Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n...          ...        ...       ...       ...            ...   ...    ...   \n8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n\n      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n...           ...        ...           ...     ...     ...                ...   \n8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n\n      Transported  \n0           False  \n1            True  \n2           False  \n3           False  \n4            True  \n...           ...  \n8688        False  \n8689        False  \n8690         True  \n8691        False  \n8692         True  \n\n[8693 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8688</th>\n      <td>9276_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/98/P</td>\n      <td>55 Cancri e</td>\n      <td>41.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>6819.0</td>\n      <td>0.0</td>\n      <td>1643.0</td>\n      <td>74.0</td>\n      <td>Gravior Noxnuther</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8689</th>\n      <td>9278_01</td>\n      <td>Earth</td>\n      <td>True</td>\n      <td>G/1499/S</td>\n      <td>PSO J318.5-22</td>\n      <td>18.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Kurta Mondalley</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8690</th>\n      <td>9279_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>G/1500/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>26.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1872.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Fayey Connon</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8691</th>\n      <td>9280_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>55 Cancri e</td>\n      <td>32.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1049.0</td>\n      <td>0.0</td>\n      <td>353.0</td>\n      <td>3235.0</td>\n      <td>Celeon Hontichre</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8692</th>\n      <td>9280_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>E/608/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>44.0</td>\n      <td>False</td>\n      <td>126.0</td>\n      <td>4688.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>Propsh Hontichre</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>8693 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"df = train_df.drop('Transported', axis=1)\ndisplayFacetStatistics(df)\n\n#displayFacetsDive(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"\n\ntrain_file = os.path.join(BASE_DIR, 'train.csv')\ntrain_file_processed = os.path.join(BASE_DIR_OUTPUT, 'train.csv')\ntest_file = os.path.join(BASE_DIR, 'test.csv')\ntest_file_processed = os.path.join(BASE_DIR_OUTPUT, 'test.csv')\n\nrun_pipeline(train_file, train_file_processed, test=False, force=True)\nrun_pipeline(test_file, test_file_processed, test=True, force=True)\n\ntrain_model(features, ['Transported'])\n#make_predictions()          ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with tf.dataset\nbatch_size = 500 # A small batch sized is used for demonstration purposes\ntrain_ds = df_to_dataset(train_df, batch_size=batch_size)\ntest_ds = df_to_dataset(test_df, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T10:55:36.906080Z","iopub.execute_input":"2022-07-23T10:55:36.906472Z","iopub.status.idle":"2022-07-23T10:55:37.024144Z","shell.execute_reply.started":"2022-07-23T10:55:36.906441Z","shell.execute_reply":"2022-07-23T10:55:37.022638Z"},"trusted":true},"execution_count":59,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m           \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    486\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 487\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for 0          B/0/P\n1          F/0/S\n2          A/0/S\n3          A/0/S\n4          F/1/S\n          ...   \n8688      A/98/P\n8689    G/1499/S\n8690    G/1500/S\n8691     E/608/S\n8692     E/608/S\nName: Cabin, Length: 8693, dtype: object with type Series","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/791721704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# with tf.dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;31m# A small batch sized is used for demonstration purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/964770475.py\u001b[0m in \u001b[0;36mdf_to_dataset\u001b[0;34m(dataframe, shuffle, batch_size)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_column\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3843\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3844\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3845\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3846\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         normalized_components.append(\n\u001b[0;32m--> 111\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    112\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                          as_ref=False):\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."],"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type float).","output_type":"error"}]},{"cell_type":"code","source":"os.remove(os.path.join(BASE_DIR_OUTPUT, 'predictions.csv'))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-23T12:51:03.601048Z","iopub.execute_input":"2022-07-23T12:51:03.601509Z","iopub.status.idle":"2022-07-23T12:51:03.607215Z","shell.execute_reply.started":"2022-07-23T12:51:03.601477Z","shell.execute_reply":"2022-07-23T12:51:03.606298Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom matplotlib import pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train_df[features]\ndisplay(train_df[features][train_df[features]['HomePlanet'] == 'Earth'])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T15:31:46.456054Z","iopub.execute_input":"2022-07-22T15:31:46.456442Z","iopub.status.idle":"2022-07-22T15:31:46.487692Z","shell.execute_reply.started":"2022-07-22T15:31:46.456413Z","shell.execute_reply":"2022-07-22T15:31:46.486930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pandas_to_numpy(data):\n    '''Convert a pandas DataFrame into a Numpy array'''\n  # Drop empty rows.\n    data = data.dropna(how=\"any\", axis=0)\n  # Separate DataFrame into two Numpy arrays.\n    labels = np.array(data['Transported'])\n    features = data.drop('Transported', axis=1)\n    features = {name:np.array(value) for name, value in features.items()}\n  \n    return features, labels\n\n#@title Visualize Binary Confusion Matrix and Compute Evaluation Metrics Per Subgroup\nCATEGORY  =  \"HomePlanet\" #@param {type:\"string\"}\nSUBGROUP =  1 #@param {type:\"int\"}\n\n# Labels for annotating axes in plot.\nclasses = ['Transported', 'Not Transported']\n\n# Given define subgroup, generate predictions and obtain its corresponding \n# ground truth.\nsubgroup_filter  = train_df.loc[train_df[CATEGORY] == SUBGROUP]\nfeatures, labels = pandas_to_numpy(subgroup_filter)\n\nsubgroup_results = model.evaluate(x=features, y=labels, verbose=0)\ndisplay(subgroup_filter)\nconfusion_matrix = np.array([[subgroup_results[1], subgroup_results[4]], \n                             [subgroup_results[2], subgroup_results[3]]])\n\nsubgroup_performance_metrics = {\n    'ACCURACY': subgroup_results[5],\n    'PRECISION': subgroup_results[6], \n    'RECALL': subgroup_results[7],\n    'AUC': subgroup_results[8]\n}\nperformance_df = pd.DataFrame(subgroup_performance_metrics, index=[SUBGROUP])\npd.options.display.float_format = '{:,.4f}'.format\n\nplot_confusion_matrix(confusion_matrix, classes, SUBGROUP);\nperformance_df","metadata":{"execution":{"iopub.status.busy":"2022-07-22T15:31:57.176504Z","iopub.execute_input":"2022-07-22T15:31:57.177495Z","iopub.status.idle":"2022-07-22T15:31:57.218055Z","shell.execute_reply.started":"2022-07-22T15:31:57.177444Z","shell.execute_reply":"2022-07-22T15:31:57.216622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}