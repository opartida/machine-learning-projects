{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import datetime, calendar\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer  \n",
    "from sklearn import preprocessing\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train.csv\", sep=\";\")    \n",
    "X_test = pd.read_csv(\"test.csv\", sep=\";\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ID and TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('ID',  axis='columns', inplace=True)\n",
    "X_train.drop('TIMESTAMP',  axis='columns', inplace=True)\n",
    "X_test.drop('TIMESTAMP',  axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with empty fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = {month.lower(): index for index, month in enumerate(calendar.month_name) if month}\n",
    "def replaceMonthName(date):\n",
    "    index = date.find(\"/\")\n",
    "    month_name = f\"{date[index+1:]}\".lower()\n",
    "    return date[:index] + f\"{month_names[month_name]}\".zfill(2)\n",
    "\n",
    "def processDates(data):\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].str.replace(\"-\",\"/\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].str.replace(\"-\",\"/\")\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    \n",
    "processDates(X_train)\n",
    "processDates(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert distance to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['DISTANCE'] = X_train['DISTANCE'].str.strip()\n",
    "X_train['DISTANCE'] = X_train['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_test['DISTANCE'] = X_test['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_train['DISTANCE'] = pd.to_numeric(X_train['DISTANCE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    oe_style = OneHotEncoder(handle_unknown = 'ignore')   \n",
    "    \n",
    "    for col in columns:        \n",
    "        X_train_enc = oe_style.fit_transform(X_train[[col]])\n",
    "        X_train = X_train.join(pd.DataFrame(X_train_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_test_enc = oe_style.transform(X_test[[col]])   \n",
    "        X_test = X_test.join(pd.DataFrame(X_test_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_train = X_train.drop([col], axis=1)\n",
    "        X_test = X_test.drop([col], axis=1)   \n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def binary_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    \n",
    "    for col in columns:   \n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "hot_encode_cols = ['WEBSITE','DEVICE','HAUL_TYPE','TRIP_TYPE', 'PRODUCT']\n",
    "label_encode_cols = ['TRAIN', 'SMS']\n",
    "\n",
    "[X_train, X_test] = hot_encode_categorical_inputs(X_train, X_test, hot_encode_cols)\n",
    "[X_train, X_test] = binary_encode_categorical_inputs(X_train, X_test, label_encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test, columns):\n",
    "    # copy the data\n",
    "    train = X_train.copy()\n",
    "    test = X_test.copy()\n",
    "    normalizer = preprocessing.MinMaxScaler()\n",
    "    for column in columns:\n",
    "        train[column] = normalizer.fit_transform(np.array(train[column]).reshape(-1,1))\n",
    "        test[column] = normalizer.transform(np.array(test[column]).reshape(-1,1))\n",
    "    return train, test\n",
    "    \n",
    "[X_train, X_test] = normalize(X_train, X_test, ['DISTANCE', 'DEPARTURE', 'ARRIVAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9799\n",
       "dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_targets(y_train):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)    \n",
    "    y_train_enc = pd.DataFrame(y_train_enc)\n",
    "    return y_train_enc\n",
    "\n",
    "Y_train = X_train['EXTRA_BAGGAGE']\n",
    "X_train = X_train.drop('EXTRA_BAGGAGE',  axis='columns')\n",
    "\n",
    "Y_train = prepare_targets(Y_train)\n",
    "Y_train.isin([1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(\"IDs.pickle\", X_test[\"ID\"].values)\n",
    "X_test = X_test.drop('ID',  axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxcVZn/8c/Tezr7vm9AAgkoAWLYRAigP0AERRBBR8H8ABVQ9Oc44gKCzoyKjjiOAwIKAgIiOpjBSFSSIC5AFkjIQshOOh3oztLpdHrven5/3NtJpenlpsmtW931fb9e9br7raeWrqfvOfecY+6OiIjkrrykAxARkWQpEYiI5DglAhGRHKdEICKS45QIRERyXEHSARyqYcOG+aRJk5IOQ0SkR1m6dOkOdx/e3rYelwgmTZrEkiVLkg5DRKRHMbMtHW1T0ZCISI5TIhARyXFKBCIiOU6JQEQkxykRiIjkuNgSgZn93MwqzGxlB9vNzP7TzNab2QozOzGuWEREpGNxXhE8AJzXyfbzgSnh41rgrhhjERGRDsTWjsDd/2JmkzrZ5WLgQQ/6wX7ezAaZ2Wh33x5XTCK9VSrlNKeclpTTlErR0pK23JKiJW37/ocHUw+nKQfHcYeUh8t+YHn/lPT1Bx/j4XIqxUH7HdjnwLwD7D9fuG/rfPi6WrvJbz1H6zyk79O6fPD2tsen6+hY2qxP3zeyGLv2P2faSI4fP+iwnzfJBmVjga1py2XhurckAjO7luCqgQkTJmQkOJGuuDt1TS3sa2ihtrGZ2sYD07rGFuqaWmhoSlHf3EJjc4qG8NHY+mgJ1je1eLicCpeDR7DOaW5pXRf8qDengnXB1GlOpUhpWJGsYhbPeUcMKOl1iaC9t6rdr7O73wPcAzBz5kx95eVta2xOsaeuKXw0sqeuieq6Zqrrm6iua6K6vpmahmZqWqcNzexrCH7kaxqaqW1oprappVv//BUV5FGcn0dRQR6F+6dGUUF+MA3XlRYVhNuNgrw8CsJtBfnhcp5RkB8cm59n+5cL8g5ebp0PpsFy8IA8C+bzzDALlg/Mg5lhHLye1uU8MN66r5kFy+E2s3bWAbRZPnB8sL71F6Lt9tZ1wSnsoGXa2X5gvu0+dtD6t54jpl/zLJRkIigDxqctjwPKE4pFeqhUytlb38yu2kZ27WukqraR3bVN4bSRqtomqmqb9s/vqQu27Wts6fS8RQV5DCgpoF9xAf1KCuhbVMCoASWUFhfQtyifvuG0tLiA0qJ8+hYF09blPoX5lBTmU1KYR3HBgWlhvuXUD4z0DEkmgrnADWb2GHAysEf1A9KqvqmFst11lFfVUbG3gYq99VRUN1BZ08CumkZ27mtg177gR7+lg3KR/DxjUJ9CBpYWMri0iNEDS5g2egCDSgsZ2Kdw/zT9MaBPIf1LCiguyM/wKxZJTmyJwMweBc4ChplZGXArUAjg7ncD84ALgPVALXB1XLFIdqpvamHdmzVs3FHDph372LxjH5t31lK2u44dNQ1v2b9/cQHD+xczpG8Rk4f15aSJQxjat4jBfYsY0reQQaVFDC4tYnBpMN+/uIC8PP33LdKVOO8auqKL7Q5cH9fzS3apb2phVXk1y7dWsXLbHlZvr2ZdRc3+/+bNYMzAPkwcWsq500YwbnAfxg7uw5iBfRg5oIQRA4opLepxneWK9Aj6y5JYVFTXs3jzbhZv3sWy13ezZns1TS3Bj/6I/sUcO2YA50wbwbFjBnLUiH5MGFJKSaGKY0SSoEQgh03Z7loeX1LG3Je3sXlnLQB9CvOZMX4Q//eMIzh+3CBmjB/EqIElCUcqIumUCORtaW5J8ec1b/LIi1t5bl0lAO8+ahgfO3ki75o8hGPHDKAwX11aiWQzJQLplqraRh5bvJWH/rGFbVV1jB5Ywo1nT+Gyk8Yxfkhp0uGJyCFQIpBDUl5Vx93PbuDxJVupb0pxyhFDuOUD0zl32kjydYeOSI+kRCCRlFfVcdeiDfxq8VYc50MnjOXq0yczbfSApEMTkbdJiUA6tXtfIz9esJ6Hn99Cyp3LZo7n+tlHMm6win9EegslAmlXQ3MLD/59Cz9esI6ahmYuO2k8N5x9lMr/RXohJQI5iLsz75U3+O7Tr/L6rlrOnDqcr14wjaNH9U86NBGJiRKB7PfS67v59u/XsHTLbo4Z1Z8HPzWL90wdnnRYIhIzJQLhjT31/Psf1vC7l8sZ3r+Y71zyDi6bOV53AYnkCCWCHNbYnOLnf9vEfz6zjpaUc+PZR3HdmUfSr1hfC5Fcor/4HPX3DTv4xpMr2VC5j3OnjeTWD0xXRbBIjlIiyDENzS18f/5a7n1uExOHlnL/Ve9i9jEjkg5LRBKkRJBD1lfU8PnHXmJVeTX/dMpEvnrBNPoUqcdPkVynRJAjfrO0jK89+Qp9CvO59xMzee/0kUmHJCJZQomgl2tJOd/5wxrufW4Tpx05lDsvn8GIAeoGWkQOUCLoxarrm/jcoy+xaG0lV502ia+/fxoF6hJaRNroMhGY2Ujg34Ax7n6+mU0HTnX3n8UenXTb1l21XHX/i2zZWcu/fug4PnbyxKRDEpEsFeXfwweA+cCYcPk14Ka4ApK3b832ai656+/sqGnkoTknKwmISKeiJIJh7v44kAJw92agJdaopNte3LSLj/z0HxTkGU98+lROPXJo0iGJSJaLUkewz8yGAg5gZqcAe2KNSrrlz6vf5PpHljF2cB8emnMyYwf1STokEekBoiSCLwJzgSPN7G/AcODSWKOSQ/b0yje4/pFlHDdmAPdfPYshfYuSDklEeoguE4G7LzOzM4GjAQPWuntT7JFJZIvWVnDjo8s4ftxAHpxzsvoKEpFD0mUdgZldD/Rz91XuvhLoZ2afjT80ieIfG3Zy3UNLOXpUf+6/epaSgIgcsiiVxde4e1XrgrvvBq6JLySJaumW3cz5xWImDi3lwU+dzMA+hUmHJCI9UJREkGdm+zumN7N8QAXQCdu8Yx+femAxI/oX8/Cck1UnICLdFqUcYT7wuJndTXDn0KeBp2ONSjpVXd/EnF8sxgx+8alZ6jJCRN6WKIngX4DrgM8QVBb/EbgvzqCkYy0p58ZHXmLLzloemnMyE4f2TTokEenhotw1lALuCh+SsH+bt4ZnX6vk3y95hxqLichhEaWvodOBbwITw/0NcHc/It7QpK3HF2/lZ3/dxFWnTeKKWROSDkdEeokoRUM/A74ALEVdSyRm2eu7+fqTKzljyjC+/v5pSYcjIr1IlESwx93/EHsk0qE3q+v59ENLGTWwhB9fcYK6khaRwypKIlhoZncAvwUaWle6+7LYopL96ptauPahpdQ0NPPQnJMZVKrbREXk8IqSCE4OpzPT1jlw9uEPR9K5O19/ciXLt1Zx98dP4uhR/ZMOSUR6oSh3Dc3ORCDyVg8/v4UnlpbxuXOmcN5xo5IOR0R6qUgd05jZ+4Fjgf0tl9z99riCEnjp9d3c/tRqzj5mBDedMyXpcESkF4vS6dzdwOXAjQS3jl5GcCupxGTXvkau/+UyRg4o4YcfmUFennV9kIhIN0W5/eQ0d/8EsNvdbwNOBcZHObmZnWdma81svZl9pZ3tE8xsoZm9ZGYrzOyCQwu/92lJOTf96mV21DRy18dOYmCpOpITkXhFSQR14bTWzMYATcDkrg4KO6f7CXA+MB24Ihz4Pt3Xgcfd/QTgo8B/Rw28t/rxgnX85bVKbr1oOu8YNzDpcEQkB0RJBE+Z2SDgDmAZsBl4LMJxs4D17r7R3RvDYy5us48DA8L5gUB5lKB7qyWbd/GjZ9ZxyQljuVIth0UkQ6LcNfStcPY3ZvYUUOLuUcYsHgtsTVsu48CtqK2+CfzRzG4E+gLntnciM7sWuBZgwoTe+QNZ39TCl59YwdhBffjWB48jredvEZFYdZgIzOxsd19gZpe0sw13/20X527vl8zbLF8BPODuPzCzU4GHzOy4sKO7Awe53wPcAzBz5sy25+gV7vzzOjbu2MdDc2bRV6OMiUgGdfaLcyawAPhAO9ucoKVxZ8o4uFJ5HG8t+pkDnAfg7v8wsxJgGFDRxbl7lRVlVdz73EYunzmeM6YMTzocEckxHSYCd7/VzPKAP7j7490492JgiplNBrYRVAZf2Waf14FzgAfMbBpBO4XKbjxXj9XYnOLLT6xgWL8ivqrO5EQkAZ1WFodFNDd058Tu3hweOx9YQ3B30Cozu93MLgp3+3/ANWa2HHgUuMrde2XRT0fuWrSBV9/Yy7c/+A6NOSwiiYhSGP0nM/sS8CtgX+tKd9/V1YHuPg+Y12bdLWnzq4HTI0fby6yvqOG/Fq7jA8eP4b3TRyYdjojkqCiJ4FPh9Pq0dQ5oYJq3wd35xpMrKSnM55YL2zavEBHJnCi3j3bZeEwO3ZMvb+MfG3fy7Q8ex/D+xUmHIyI5LGqnc8cRtA5O73TuwbiC6u321Dbx7afWMGP8IDUcE5HERRmz+FbgLIJEMI+gy4i/AkoE3fTd+a+yu7aRB+fMUodyIpK4KF1MXEpwi+cb7n41cDygsoxuWrplN4+88DpXnz6ZY8eoLyERSV6kTufC20ibzWwAQWMvVRR3Qyrl3Dp3JSMHFPOF905NOhwRESBaHcGSsNO5e4GlQA3wYqxR9VK/WVbGym3V3Hn5DPqpGwkRyRJR7hr6bDh7t5k9DQxw9xXxhtX71DQ08735azlhwiAunjEm6XBERPaLMkLZ78zsSjPr6+6blQS6565F66nc28A3LpyunkVFJKtEqSP4D+DdwGoz+7WZXRp2DicRbd1Vy73PbeKDM8Zw4oTBSYcjInKQKEVDzwLPhiOOnQ1cA/ycAwPKSBe+84dXyTP4l/OPSToUEZG3iNqgrA9Bd9SXAycCv4gzqN7kxU27+P0r27np3CmMHtgn6XBERN4iSoOyXxGMLPY0wRjEi9oOHCPtc3f+dd4aRg0o4br3HJl0OCIi7YpyRXA/cKW7t8QdTG/z1IrtLN9axfcufSd9ivKTDkdEpF1R6giezkQgvU1Dcwvfm/8qx4zqz4dPHJd0OCIiHYpy15B0w8PPv87WXXXcfME08tWfkIhkMSWCGOypa+LHC9ZxxpRhnDlVYxCLSHbrsGjIzE7s7EB3X3b4w+kd/nvhevbUNfEV3S4qIj1AZ3UEPwinJcBMYDlgwDuBFwgamUkb5VV13P/3zXzohLHqXVREeoQOi4bcfba7zwa2ACe6+0x3Pwk4AVifqQB7mrsWbcDd+aJ6FxWRHiJKHcEx7v5K64K7rwRmxBdSz/XGnnp+tXgrl540jnGDS5MOR0QkkijtCNaY2X3AwwSD1n8cWBNrVD3U3c9uIOXOZ886KulQREQii5IIrgY+A3w+XP4LcFdsEfVQFdX1PPLi61xy4ljGD9HVgIj0HFEalNWb2d3APHdfm4GYeqS7n91IS8q5YfaUpEMRETkkUcYjuAh4maCvIcxshpnNjTuwnqRibz2/fGELHzphLBOG6mpARHqWKJXFtwKzgCoAd38ZmBRjTD3OvX/ZSFNLiutnq25ARHqeKImg2d33xB5JD9XYnOLRF7fygePHMHlY36TDERE5ZFEqi1ea2ZVAvplNAT4H/D3esHqOFzftoqahmQ+8U+MQi0jPFOWK4EbgWKABeBSoBm6KM6ie5JlX36SoII/TjhqadCgiIt0S5a6hWuBr4UPaWPhqBaceMZTSokiDvYmIZJ0oI5RNBb5EUEG8f393Pzu+sHqGjZU1bN5Zy9WnT046FBGRbovyb+yvgbuB+wCNUpZmwasVAJx9zIiEIxER6b4oiaDZ3dWSuB0L11YwZUQ/tSQWkR4tSmXx/5rZZ81stJkNaX3EHlmW21vfxIubdulqQER6vChXBJ8Mp/+cts6BIw5/OD3HX9ftoKnFma1EICI9XJS7hlQT2o4Fr1bQv6SAkyYOTjoUEZG3pbOhKs929wVmdkl72939t/GFld1SKWfh2kreM3U4hfka9llEerbOrgjOBBYAH2hnmwM5mwhWlu9hR00D56hYSER6gQ4TgbvfGk6v7u7Jzew84EdAPnCfu3+nnX0+AnyTILksd/cru/t8mbLg1QrM4Mypw5MORUTkbYvUHNbM3k/QzURJ6zp3v72LY/KBnwDvBcqAxWY2191Xp+0zBbgZON3dd5tZj/gXe+HaSo4fN4ih/YqTDkVE5G2LMh7B3cDlBH0OGXAZMDHCuWcB6919o7s3Ao8BF7fZ5xrgJ+6+G8DdKw4h9kTsqGlgRVmVbhsVkV4jSk3nae7+CWC3u98GnAqMj3DcWGBr2nJZuC7dVGCqmf3NzJ4Pi5Ky2l9eq8QdZh+tRCAivUOUoqG6cFprZmOAnUCUW0qtnXXezvNPAc4CxgHPmdlx7l510InMrgWuBZgwYUKEp47PwrWVDOtXzLFjBiQah4jI4RLliuApMxsE3AEsAzYTFPN0pYyDrxzGAeXt7PM7d29y903AWoLEcBB3v8fdZ7r7zOHDk6ugbW5J8ZfXKjlz6nDy8trLcyIiPU+XicDdv+XuVe7+G4K6gWPc/RsRzr0YmGJmk82sCPgo0Has4yeB2QBmNoygqGjjobyATFpeVsWeuiZmH6O7hUSk9+isQVm7DcnCbV02KHP3ZjO7AZhPcPvoz919lZndDixx97nhtveZ2WqCnk3/2d13dueFZMLCVyvJzzPOOEqJQER6j87qCNprSNYqUoMyd58HzGuz7pa0eQe+GD6y3sK1FZw0YTADSwuTDkVE5LDprEFZtxuS9UZvVtezqryaL593dNKhiIgcVlHaEQw1s/80s2VmttTMfmRmOTdA77NrKwHdNioivU+Uu4YeAyqBDwOXhvO/ijOobLTotQpGDSjhmFH9kw5FROSwipIIhoR3Dm0KH98GBsUdWDZpaknx3Gs7OOvo4ZjptlER6V2iJIKFZvZRM8sLHx8Bfh93YNlk6Zbd7G1o5iwVC4lILxQlEVwHPAI0hI/HgC+a2V4zq44zuGzxjw07yTM4/aicqxoRkRwQZYSynC8UX15WxdSR/elfottGRaT3iXLX0Jw2y/lmdmt8IWUXd2f51iqOH5dT1SIikkOiFA2dY2bzzGy0mb0DeB7ImauE13fVsru2iePHKxGISO8UpWjoSjO7HHgFqAWucPe/xR5Zlnh5a9AR6vHjByYciYhIPKIUDU0BPg/8hqDn0X8ys9KY48oay7fuoaQwj6NH5sxFkIjkmChFQ/8L3OLu1xEMaL+OoGfRnLC8rIp3jB1IQX6Ut0pEpOeJ8us2y93/DEEnce7+A+CD8YaVHZpaUqzctkcVxSLSq0VJBM1m9g0zuxf2FxXlRM9ra9/YS0NzShXFItKrRUkE9xM0JDs1XC4Dvh1bRFmktaJ4hhKBiPRiURLBke7+PaAJwN3raH884l5n+dYqhvQtYtzgPkmHIiISmyiJoNHM+hAOPG9mRxJcIfR6y8uqmDF+kDqaE5FeLUoiuBV4GhhvZr8EngG+HGtUWaCmoZl1FTWqKBaRXi9Kg7I/mdky4BSCIqHPu/uO2CNL2Ctle3BXQzIR6f26TAQA4YDyOdX19PKysEWxrghEpJdTK6kOLN9axcShpQzuW5R0KCIisVIi6MDL6nFURHJEpERgZu82s6vD+eFmNjnesJJVUV3P9j31aj8gIjkhSqdztwL/AtwcrioEHo4zqKStLN8DwDvGqaJYRHq/KFcEHwIuAvYBuHs5vXw8glXbqjGDaaMHJB2KiEjsIjUoc3fnQIOyvvGGlLzV26uZNLQv/Yoj3VQlItKjRUkEj5vZT4FBZnYN8Gfg3njDStaq8mqm62pARHJElAZl3zez9wLVBL2O3uLuf4o9soRU1zfx+q5aLn/X+KRDERHJiC4TgZl9Afh1b/7xT7emvBqA6WN0RSAiuSFK0dAAYL6ZPWdm15vZyLiDStLq7UEiOFZFQyKSI7pMBO5+m7sfC1wPjAGeNbM/xx5ZQlaVVzOsXzEjBpQkHYqISEYcSsviCuANYCcwIp5wkre6vFrFQiKSU6I0KPuMmS0i6H56GHCNu78z7sCS0NicYl3FXo5VIhCRHBLlRvmJwE3u/nLcwSRtXcVemlpct46KSE7pMBGY2QB3rwa+Fy4PSd/u7rtiji3jVoV3DOmKQERySWdXBI8AFwJLCVoVp4/X6MARMcaViNXl1ZQW5TNpaK9vPC0isl+HicDdLwynvbqn0XSrt1czbfQA8vI0RrGI5I4olcXPRFnX06VSzhp1LSEiOajDRGBmJWG9wDAzG2xmQ8LHJIL2BF0ys/PMbK2ZrTezr3Sy36Vm5mY281BfwOFStruOvQ3Nqh8QkZzTWR3BdcBNBD/6SzlQR1AN/KSrE5tZfrjfe4EyYLGZzXX31W326w98DnjhkKM/jFaFYxCoDYGI5JoOrwjc/Udh/cCX3P0Id58cPo539/+KcO5ZwHp33+jujcBjwMXt7PctgjuT6rvzAg6X1duryc8zpo7s1UMtiIi8RZTeR39sZscB04GStPUPdnHoWGBr2nIZcHL6DmZ2AjDe3Z8ysy9FjjoGq8qrOWp4P0oK85MMQ0Qk46L0PnorcBZBIpgHnA/8FegqEbR3642nnTcP+CFwVYQYrgWuBZgwYUJXu3fL6vJqTj1yaCznFhHJZlH6GroUOAd4w92vBo4HiiMcVwakd+o/DihPW+4PHAcsMrPNwCnA3PYqjN39Hnef6e4zhw8fHuGpD011fRNvVNdz9CgVC4lI7omSCOrcPQU0m9kAgs7nojQmWwxMMbPJZlYEfBSY27rR3fe4+zB3n+Tuk4DngYvcfckhv4q3aUNFDQBHDu+X6acWEUlclL6GlpjZIILhKZcCNcCLXR3k7s1mdgMwH8gHfu7uq8zsdmCJu8/t/AyZs6FyHwBHDleLYhHJPVEqiz8bzt5tZk8DA9x9RZSTu/s8gnqF9HW3dLDvWVHOGYcNlTUU5hsThpQmFYKISGI663TuxM62ufuyeELKvPUVNUwa2peC/EMZnkFEpHfo7IrgB51sc+DswxxLYjZU1jB1hCqKRSQ3ddbp3OxMBpKUppYUr++s5YLjRicdiohIIqK0I/hEe+sjNCjrEbbs3EdzyjlyhCqKRSQ3Rblr6F1p8yUEbQqW0XWDsh5hfUXrHUO6dVREclOUu4ZuTF82s4HAQ7FFlGEbKtWGQERyW3duk6kFphzuQJKyoaKG0QNL6Fsc5eJIRKT3iVJH8L8c6CMoj6DPocfjDCqTNlTW6GpARHJalH+Dv5823wxscfeymOLJKHdnQ+U+Lj1pXNKhiIgkJkodwbMAYT9DBeH8EHffFXNssXuzuoGahmZ1LSEiOS1K0dC1BIPH1AEpgu6lnWgdz2U1VRSLiEQrGvpn4Fh33xF3MJnWmgiOGqFEICK5K8pdQxsI7hTqddZX1NC/uIDh/aMMryAi0jtFuSK4Gfi7mb0ANLSudPfPxRZVhmyorOGIEf0wa28wNRGR3BAlEfwUWAC8QlBH0GtsqNjH6UcNSzoMEZFERUkEze7+xdgjybC94fCU6mNIRHJdlDqChWZ2rZmNNrMhrY/YI4vZxkr1MSQiAtGuCK4Mpzenrevxt4/qjiERkUCUBmWTMxFIpq2vqKEgT8NTiojk7HgEGyv3MXFoKYUanlJEclzOjkewdXetrgZERMjh8Qi2VdVxwoRBSYchIpK4nByPYF9DM1W1TYwZ1CfpUEREEpeT4xGUV9UBMFaJQEQkN8cjKAsTwbjBSgQiIh0mAjM7ChjZOh5B2vozzKzY3TfEHl1Mtu1uvSJQZbGISGd1BHcCe9tZXxdu67G2VdVRmG+MUK+jIiKdJoJJ7r6i7Up3XwJMii2iDNi2u45RA0vIy1OvoyIinSWCkk629ejC9W1VdaooFhEJdZYIFpvZNW1XmtkcYGl8IcWvvKpO9QMiIqHO7hq6CfgfM/sYB374ZwJFwIfiDiwuTS0p3qyuZ6zuGBIRATpJBO7+JnCamc0GjgtX/97dF2Qkspi8saeelMM4FQ2JiADRuphYCCzMQCwZURbeOqpWxSIigZzrenNba6tiFQ2JiAC5mAjCK4LRAzu7KUpEJHfkXCIor6pjeP9iSgrzkw5FRCQr5FwiUBsCEZGDKRGIiOS4nEoEqZQHiUAVxSIi+8WaCMzsPDNba2brzewr7Wz/opmtNrMVZvaMmU2MM54d+xpobE7pikBEJE1sicDM8oGfAOcTDGZzhZlNb7PbS8BMd38n8ATwvbjigfTup5UIRERaxXlFMAtY7+4b3b0ReAy4OH0Hd1/o7rXh4vPAuBjjobyqHlBjMhGRdHEmgrHA1rTlsnBdR+YAf2hvg5lda2ZLzGxJZWVltwPaVhXkHNURiIgcEGciaK+zf29nHWb2cYIO7e5ob7u73+PuM9195vDhw7sd0LbddfQvLmBgn8Jun0NEpLeJMmZxd5UB49OWxwHlbXcys3OBrwFnuntDjPHojiERkXbEeUWwGJhiZpPNrAj4KDA3fQczOwH4KXCRu1fEGAsQdDinimIRkYPFlgjcvRm4AZgPrAEed/dVZna7mV0U7nYH0A/4tZm9bGZzOzjdYbGtqk4VxSIibcRZNIS7zwPmtVl3S9r8uXE+f7rq+ib21jeraEhEpI2caVlcXqU2BCIi7cmZRLC/MZmuCEREDpI7iSC8ItAQlSIiB8uZRDBqQAnvmz6SYf2Kkw5FRCSrxFpZnE3ed+wo3nfsqKTDEBHJOjlzRSAiIu1TIhARyXFKBCIiOU6JQEQkxykRiIjkOCUCEZEcp0QgIpLjlAhERHKcubc7aFjWMrNKYEs3Dx8G7DiM4Rwu2RhXNsYEiutQZGNMkJ1xZWNMcHjjmuju7Q7x2OMSwdthZkvcfWbScbSVjXFlY0yguA5FNsYE2RlXNsYEmYtLRUMiIjlOiUBEJMflWiK4J+kAOpCNcWVjTKC4DkU2xgTZGVc2xgQZiiun6ghEROStcu2KQERE2lAiEBHJcTmTCMzsPDNba2brzewrCcbxczOrMLOVaeuGmNmfzGxdOB2c4ZjGm9lCM1tjZqvM7PNZEleJmb1oZsvDuG4L1082sxfCuH5lZkWZjCuMId/MXjKzp7Iops1m9raLLQsAAAgiSURBVIqZvWxmS8J1SX+Gg8zsCTN7Nfx+nZoFMR0dvketj2ozuykL4vpC+D1faWaPht//jHyvciIRmFk+8BPgfGA6cIWZTU8onAeA89qs+wrwjLtPAZ4JlzOpGfh/7j4NOAW4Pnx/ko6rATjb3Y8HZgDnmdkpwHeBH4Zx7QbmZDgugM8Da9KWsyEmgNnuPiPt3vOkP8MfAU+7+zHA8QTvWaIxufva8D2aAZwE1AL/k2RcZjYW+Bww092PA/KBj5Kp75W79/oHcCowP235ZuDmBOOZBKxMW14LjA7nRwNrE36/fge8N5viAkqBZcDJBC0tC9r7bDMUyziCH4qzgacASzqm8Hk3A8ParEvsMwQGAJsIb0rJhpjaifF9wN+SjgsYC2wFhhAMIfwU8H8y9b3KiSsCDrzJrcrCddlipLtvBwinI5IKxMwmAScAL2RDXGERzMtABfAnYANQ5e7N4S5JfJZ3Al8GUuHy0CyICcCBP5rZUjO7NlyX5Gd4BFAJ3B8Wo91nZn0TjqmtjwKPhvOJxeXu24DvA68D24E9wFIy9L3KlURg7azTfbNtmFk/4DfATe5enXQ8AO7e4sEl/DhgFjCtvd0yFY+ZXQhUuPvS9NXt7JrE9+t0dz+RoAj0ejN7TwIxpCsATgTucvcTgH1kvmiqQ2F5+0XAr7MglsHAxcBkYAzQl+BzbCuW71WuJIIyYHza8jigPKFY2vOmmY0GCKcVmQ7AzAoJksAv3f232RJXK3evAhYR1GEMMrOCcFOmP8vTgYvMbDPwGEHx0J0JxwSAu5eH0wqCMu9ZJPsZlgFl7v5CuPwEQWLIlu/V+cAyd38zXE4yrnOBTe5e6e5NwG+B08jQ9ypXEsFiYEpYA19EcDk4N+GY0s0FPhnOf5KgjD5jzMyAnwFr3P0/siiu4WY2KJzvQ/DHsgZYCFyaRFzufrO7j3P3SQTfowXu/rEkYwIws75m1r91nqDseyUJfobu/gaw1cyODledA6xOMqY2ruBAsRAkG9frwClmVhr+Pba+V5n5XiVVSZPpB3AB8BpBGfPXEozjUYIywCaC/5jmEJQxPwOsC6dDMhzTuwkuOVcAL4ePC7IgrncCL4VxrQRuCdcfAbwIrCe4rC9O6LM8C3gqG2IKn395+FjV+h3Pgs9wBrAk/AyfBAYnHVMYVymwExiYti7p9+o24NXwu/4QUJyp75W6mBARyXG5UjQkIiIdUCIQEclxSgQiIjlOiUBEJMcpEYiI5DglAskIM3Mz+0Ha8pfM7JuH6dwPmNmlXe/5tp/nsrAHzYVxP1fSzOyrSccgmaNEIJnSAFxiZsOSDiRd2DNtVHOAz7r77LjiySJKBDlEiUAypZlg/NUvtN3Q9j96M6sJp2eZ2bNm9riZvWZm3zGzj1kwRsErZnZk2mnONbPnwv0uDI/PN7M7zGyxma0ws+vSzrvQzB4BXmknnivC8680s++G624haHh3t5nd0c4xXw6PWW5m3wnXzTCz58Pn/p/W/u3NbJGZ/dDM/hJeYbzLzH4b9jn/7XCfSRb04f+L8PgnzKw03HZO2InbKxaMb1Ecrt9sZreZ2bJw2zHh+r7hfovD4y4O118VPu/T4XN/L1z/HaCPBX31/zI8/vfha1tpZpcfwucuPUGmW/TpkZsPoIagW+LNwEDgS8A3w20PAJem7xtOzwKqCLoELga2AbeF2z4P3Jl2/NME/9hMIWixXQJcC3w93KeYoIXr5PC8+4DJ7cQ5hqC5/3CCTtMWAB8Mty0i6C++7THnA38HSsPlIeF0BXBmOH97WryLgO+mvY7ytNdYRtDCdRJBa+/Tw/1+Hr5nJQQ96U4N1z9I0Ekg4Xt7Yzj/WeC+cP7fgI+H84MIWtj3Ba4CNoafRwmwBRif/hmE8x8G7k1bHtj2PdCjZz90RSAZ40GPpg8SDMAR1WJ33+7uDQTdg/wxXP8KwY9lq8fdPeXu6wh+3I4h6G/nExZ0Y/0CwQ/slHD/F919UzvP9y5gkQedfzUDvwS66sXzXOB+d68NX+cuMxsIDHL3Z8N9ftHmPK19Xb0CrEp7jRs50EHiVnf/Wzj/MMEVydEEnZO91sF5WzsMXMqB9+d9wFfC92ERwY/+hHDbM+6+x93rCfq2mdjO63uF4Irru2Z2hrvv6eL9kB6moOtdRA6rOwkGmLk/bV0zYTFl2OFW+nB8DWnzqbTlFAd/f9v2leIE3UPf6O7z0zeY2VkEVwTtaa9L6a5YO8/flfTX0fY1tr6ujl5TlPO2pJ3HgA+7+9r0Hc3s5DbPnX7MgSd1f83MTiLof+rfzeyP7n57F3FID6IrAskod98FPM7BQ+5tJhgyEII+2Qu7cerLzCwvrDc4gmC0qfnAZyzoYhszmxr2zNmZF4AzzWxYWJF8BfBsF8f8EfhUWhn+kPC/5t1mdka4zz9FOE9bE8zs1HD+CuCvBJ2STTKzow7hvPOBG8Mki5mdEOG5m9LetzFArbs/TDB4yomH9jIk2+mKQJLwA+CGtOV7gd+Z2YsEvT529N96Z9YS/CCOBD7t7vVmdh9B8ciy8EewEvhgZydx9+1mdjNB978GzHP3Trv+dfenzWwGsMTMGoF5BHfdfJKgcrmUoMjn6kN8TWuAT5rZTwl6xLwrfF1XA7+2oJ/6xcDdXZznWwRXYivC92EzcGEXx9wT7r+MoDjvDjNLEfSa+5lDfB2S5dT7qEgWsmDI0Kc8GMhcJFYqGhIRyXG6IhARyXG6IhARyXFKBCIiOU6JQEQkxykRiIjkOCUCEZEc9/8B5L5/OOFKkQMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=82)\n",
    "pca.fit(X_train)\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "fig.savefig('Cumulative explained variance.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca_std = np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close() \n",
    "\n",
    "\n",
    "saveData(\"X_train.pickle\", X_train)\n",
    "saveData(\"Y_train.pickle\", Y_train.values)\n",
    "saveData(\"X_test.pickle\", X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 2s 73ms/step - loss: 0.5522 - accuracy: 0.8050 - val_loss: 0.4940 - val_accuracy: 0.7979\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.8040 - val_loss: 0.4728 - val_accuracy: 0.7979\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4712 - accuracy: 0.8033 - val_loss: 0.4701 - val_accuracy: 0.7979\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4650 - accuracy: 0.8053 - val_loss: 0.4687 - val_accuracy: 0.7979\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4636 - accuracy: 0.8049 - val_loss: 0.4677 - val_accuracy: 0.7979\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4665 - accuracy: 0.8027 - val_loss: 0.4668 - val_accuracy: 0.7979\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4626 - accuracy: 0.8037 - val_loss: 0.4656 - val_accuracy: 0.7979\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.8036 - val_loss: 0.4653 - val_accuracy: 0.7979\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.8057 - val_loss: 0.4645 - val_accuracy: 0.7979\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4577 - accuracy: 0.8039 - val_loss: 0.4642 - val_accuracy: 0.7979\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4548 - accuracy: 0.8055 - val_loss: 0.4640 - val_accuracy: 0.7979\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4567 - accuracy: 0.8039 - val_loss: 0.4638 - val_accuracy: 0.7979\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4574 - accuracy: 0.8029 - val_loss: 0.4641 - val_accuracy: 0.7979\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4543 - accuracy: 0.8043 - val_loss: 0.4638 - val_accuracy: 0.7979\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4565 - accuracy: 0.8014 - val_loss: 0.4640 - val_accuracy: 0.7979\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4584 - accuracy: 0.8008 - val_loss: 0.4636 - val_accuracy: 0.7979\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.8044 - val_loss: 0.4636 - val_accuracy: 0.7979\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4534 - accuracy: 0.8031 - val_loss: 0.4638 - val_accuracy: 0.7979\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4540 - accuracy: 0.8020 - val_loss: 0.4646 - val_accuracy: 0.7982\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4499 - accuracy: 0.8041 - val_loss: 0.4642 - val_accuracy: 0.7979\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.8034 - val_loss: 0.4644 - val_accuracy: 0.7982\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4532 - accuracy: 0.8016 - val_loss: 0.4647 - val_accuracy: 0.7986\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.8014 - val_loss: 0.4655 - val_accuracy: 0.7986\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4467 - accuracy: 0.8050 - val_loss: 0.4656 - val_accuracy: 0.7982\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.8053 - val_loss: 0.4653 - val_accuracy: 0.7982\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4471 - accuracy: 0.8047 - val_loss: 0.4658 - val_accuracy: 0.7975\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4428 - accuracy: 0.8069 - val_loss: 0.4657 - val_accuracy: 0.7977\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4468 - accuracy: 0.8048 - val_loss: 0.4660 - val_accuracy: 0.7984\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4462 - accuracy: 0.8049 - val_loss: 0.4663 - val_accuracy: 0.7979\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4461 - accuracy: 0.8033 - val_loss: 0.4662 - val_accuracy: 0.7986\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4435 - accuracy: 0.8045 - val_loss: 0.4669 - val_accuracy: 0.7986\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4446 - accuracy: 0.8043 - val_loss: 0.4673 - val_accuracy: 0.7984\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4423 - accuracy: 0.8050 - val_loss: 0.4679 - val_accuracy: 0.7975\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4398 - accuracy: 0.8042 - val_loss: 0.4686 - val_accuracy: 0.7982\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4364 - accuracy: 0.8074 - val_loss: 0.4694 - val_accuracy: 0.7979\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.8054 - val_loss: 0.4698 - val_accuracy: 0.7982\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.8047 - val_loss: 0.4705 - val_accuracy: 0.7982\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4381 - accuracy: 0.8057 - val_loss: 0.4702 - val_accuracy: 0.7963\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4367 - accuracy: 0.8056 - val_loss: 0.4714 - val_accuracy: 0.7979\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4367 - accuracy: 0.8063 - val_loss: 0.4711 - val_accuracy: 0.7959\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4357 - accuracy: 0.8064 - val_loss: 0.4716 - val_accuracy: 0.7957\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.8062 - val_loss: 0.4736 - val_accuracy: 0.7961\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.8067 - val_loss: 0.4719 - val_accuracy: 0.7951\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8043 - val_loss: 0.4738 - val_accuracy: 0.7949\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.8081 - val_loss: 0.4744 - val_accuracy: 0.7947\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4319 - accuracy: 0.8059 - val_loss: 0.4760 - val_accuracy: 0.7947\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.8059 - val_loss: 0.4765 - val_accuracy: 0.7945\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4302 - accuracy: 0.8079 - val_loss: 0.4758 - val_accuracy: 0.7951\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.8097 - val_loss: 0.4774 - val_accuracy: 0.7959\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4280 - accuracy: 0.8098 - val_loss: 0.4778 - val_accuracy: 0.7917\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4258 - accuracy: 0.8126 - val_loss: 0.4796 - val_accuracy: 0.7933\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4258 - accuracy: 0.8089 - val_loss: 0.4807 - val_accuracy: 0.7951\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4239 - accuracy: 0.8101 - val_loss: 0.4807 - val_accuracy: 0.7905\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.8091 - val_loss: 0.4813 - val_accuracy: 0.7931\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4234 - accuracy: 0.8100 - val_loss: 0.4814 - val_accuracy: 0.7915\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8110 - val_loss: 0.4826 - val_accuracy: 0.7931\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.8086 - val_loss: 0.4821 - val_accuracy: 0.7919\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4215 - accuracy: 0.8121 - val_loss: 0.4827 - val_accuracy: 0.7895\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4232 - accuracy: 0.8127 - val_loss: 0.4837 - val_accuracy: 0.7919\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4187 - accuracy: 0.8129 - val_loss: 0.4848 - val_accuracy: 0.7903\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4212 - accuracy: 0.8123 - val_loss: 0.4855 - val_accuracy: 0.7911\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.8116 - val_loss: 0.4877 - val_accuracy: 0.7911\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.8135 - val_loss: 0.4903 - val_accuracy: 0.7911\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8116 - val_loss: 0.4890 - val_accuracy: 0.7905\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.8145 - val_loss: 0.4884 - val_accuracy: 0.7853\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.8102 - val_loss: 0.4888 - val_accuracy: 0.7827\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8115 - val_loss: 0.4886 - val_accuracy: 0.7861\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4178 - accuracy: 0.8130 - val_loss: 0.4910 - val_accuracy: 0.7917\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4162 - accuracy: 0.8140 - val_loss: 0.4925 - val_accuracy: 0.7887\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4153 - accuracy: 0.8135 - val_loss: 0.4924 - val_accuracy: 0.7901\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8148 - val_loss: 0.4929 - val_accuracy: 0.7849\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4106 - accuracy: 0.8171 - val_loss: 0.4944 - val_accuracy: 0.7895\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4142 - accuracy: 0.8155 - val_loss: 0.4933 - val_accuracy: 0.7867\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4124 - accuracy: 0.8153 - val_loss: 0.4945 - val_accuracy: 0.7873\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8169 - val_loss: 0.4979 - val_accuracy: 0.7895\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8179 - val_loss: 0.4991 - val_accuracy: 0.7877\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4110 - accuracy: 0.8176 - val_loss: 0.4988 - val_accuracy: 0.7855\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.8155 - val_loss: 0.5003 - val_accuracy: 0.7893\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8175 - val_loss: 0.4961 - val_accuracy: 0.7803\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.8130 - val_loss: 0.5000 - val_accuracy: 0.7821\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.8222 - val_loss: 0.5011 - val_accuracy: 0.7849\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4059 - accuracy: 0.8167 - val_loss: 0.4998 - val_accuracy: 0.7843\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4065 - accuracy: 0.8196 - val_loss: 0.5004 - val_accuracy: 0.7833\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8224 - val_loss: 0.5012 - val_accuracy: 0.7805\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4043 - accuracy: 0.8188 - val_loss: 0.5025 - val_accuracy: 0.7784\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4071 - accuracy: 0.8183 - val_loss: 0.5043 - val_accuracy: 0.7845\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4031 - accuracy: 0.8206 - val_loss: 0.5045 - val_accuracy: 0.7762\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8213 - val_loss: 0.5050 - val_accuracy: 0.7786\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4026 - accuracy: 0.8211 - val_loss: 0.5054 - val_accuracy: 0.7817\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8192 - val_loss: 0.5052 - val_accuracy: 0.7762\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8185 - val_loss: 0.5094 - val_accuracy: 0.7837\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8210 - val_loss: 0.5089 - val_accuracy: 0.7768\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3962 - accuracy: 0.8238 - val_loss: 0.5071 - val_accuracy: 0.7728\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4031 - accuracy: 0.8209 - val_loss: 0.5063 - val_accuracy: 0.7764\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4013 - accuracy: 0.8207 - val_loss: 0.5113 - val_accuracy: 0.7821\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3969 - accuracy: 0.8229 - val_loss: 0.5118 - val_accuracy: 0.7784\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.5109 - val_accuracy: 0.7797\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8227 - val_loss: 0.5102 - val_accuracy: 0.7786\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8224 - val_loss: 0.5121 - val_accuracy: 0.7825\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4011 - accuracy: 0.8215 - val_loss: 0.5116 - val_accuracy: 0.7762\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8252 - val_loss: 0.5152 - val_accuracy: 0.7803\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3938 - accuracy: 0.8242 - val_loss: 0.5149 - val_accuracy: 0.7748\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3947 - accuracy: 0.8231 - val_loss: 0.5152 - val_accuracy: 0.7789\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8251 - val_loss: 0.5180 - val_accuracy: 0.7782\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3953 - accuracy: 0.8235 - val_loss: 0.5161 - val_accuracy: 0.7736\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8254 - val_loss: 0.5177 - val_accuracy: 0.7768\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8247 - val_loss: 0.5202 - val_accuracy: 0.7795\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8234 - val_loss: 0.5179 - val_accuracy: 0.7738\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8251 - val_loss: 0.5173 - val_accuracy: 0.7662\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8260 - val_loss: 0.5214 - val_accuracy: 0.7722\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.8240 - val_loss: 0.5191 - val_accuracy: 0.7770\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3911 - accuracy: 0.8246 - val_loss: 0.5202 - val_accuracy: 0.7670\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5238 - val_accuracy: 0.7760\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8274 - val_loss: 0.5194 - val_accuracy: 0.7654\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3915 - accuracy: 0.8247 - val_loss: 0.5232 - val_accuracy: 0.7726\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8250 - val_loss: 0.5238 - val_accuracy: 0.7746\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8267 - val_loss: 0.5237 - val_accuracy: 0.7654\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8292 - val_loss: 0.5223 - val_accuracy: 0.7770\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8265 - val_loss: 0.5223 - val_accuracy: 0.7736\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8285 - val_loss: 0.5233 - val_accuracy: 0.7744\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8292 - val_loss: 0.5278 - val_accuracy: 0.7700\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8292 - val_loss: 0.5292 - val_accuracy: 0.7750\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8285 - val_loss: 0.5289 - val_accuracy: 0.7752\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8242 - val_loss: 0.5273 - val_accuracy: 0.7646\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8296 - val_loss: 0.5264 - val_accuracy: 0.7702\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8295 - val_loss: 0.5321 - val_accuracy: 0.7704\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8285 - val_loss: 0.5310 - val_accuracy: 0.7702\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3841 - accuracy: 0.8281 - val_loss: 0.5308 - val_accuracy: 0.7716\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8260 - val_loss: 0.5309 - val_accuracy: 0.7716\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3800 - accuracy: 0.8304 - val_loss: 0.5324 - val_accuracy: 0.7714\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3838 - accuracy: 0.8294 - val_loss: 0.5308 - val_accuracy: 0.7720\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 1s 77ms/step - loss: 0.3800 - accuracy: 0.8310 - val_loss: 0.5357 - val_accuracy: 0.7688\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3825 - accuracy: 0.8290 - val_loss: 0.5364 - val_accuracy: 0.7752\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3786 - accuracy: 0.8336 - val_loss: 0.5367 - val_accuracy: 0.7708\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3807 - accuracy: 0.8301 - val_loss: 0.5369 - val_accuracy: 0.7688\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3763 - accuracy: 0.8315 - val_loss: 0.5362 - val_accuracy: 0.7706\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3766 - accuracy: 0.8323 - val_loss: 0.5363 - val_accuracy: 0.7595\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8347 - val_loss: 0.5368 - val_accuracy: 0.7688\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8304 - val_loss: 0.5399 - val_accuracy: 0.7714\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3850 - accuracy: 0.8285 - val_loss: 0.5397 - val_accuracy: 0.7710\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3818 - accuracy: 0.8291 - val_loss: 0.5395 - val_accuracy: 0.7686\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3737 - accuracy: 0.8343 - val_loss: 0.5400 - val_accuracy: 0.7682\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3808 - accuracy: 0.8300 - val_loss: 0.5434 - val_accuracy: 0.7732\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3742 - accuracy: 0.8339 - val_loss: 0.5410 - val_accuracy: 0.7569\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3757 - accuracy: 0.8336 - val_loss: 0.5468 - val_accuracy: 0.7710\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3768 - accuracy: 0.8334 - val_loss: 0.5435 - val_accuracy: 0.7694\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8313 - val_loss: 0.5414 - val_accuracy: 0.7624\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3760 - accuracy: 0.8349 - val_loss: 0.5424 - val_accuracy: 0.7700\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3758 - accuracy: 0.8322 - val_loss: 0.5418 - val_accuracy: 0.7680\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3781 - accuracy: 0.8311 - val_loss: 0.5435 - val_accuracy: 0.7676\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3753 - accuracy: 0.8336 - val_loss: 0.5417 - val_accuracy: 0.7628\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8329 - val_loss: 0.5473 - val_accuracy: 0.7700\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3749 - accuracy: 0.8324 - val_loss: 0.5444 - val_accuracy: 0.7628\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.8341 - val_loss: 0.5492 - val_accuracy: 0.7706\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3738 - accuracy: 0.8323 - val_loss: 0.5494 - val_accuracy: 0.7712\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3726 - accuracy: 0.8352 - val_loss: 0.5480 - val_accuracy: 0.7610\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.8338 - val_loss: 0.5517 - val_accuracy: 0.7734\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3727 - accuracy: 0.8364 - val_loss: 0.5501 - val_accuracy: 0.7604\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3720 - accuracy: 0.8361 - val_loss: 0.5526 - val_accuracy: 0.7696\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3705 - accuracy: 0.8351 - val_loss: 0.5503 - val_accuracy: 0.7591\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.8356 - val_loss: 0.5495 - val_accuracy: 0.7634\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.3726 - accuracy: 0.8356 - val_loss: 0.5542 - val_accuracy: 0.7690\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3682 - accuracy: 0.8353 - val_loss: 0.5525 - val_accuracy: 0.7666\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8350 - val_loss: 0.5501 - val_accuracy: 0.7610\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3719 - accuracy: 0.8339 - val_loss: 0.5542 - val_accuracy: 0.7692\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3672 - accuracy: 0.8375 - val_loss: 0.5523 - val_accuracy: 0.7593\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3668 - accuracy: 0.8365 - val_loss: 0.5549 - val_accuracy: 0.7642\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3689 - accuracy: 0.8369 - val_loss: 0.5573 - val_accuracy: 0.7676\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3701 - accuracy: 0.8370 - val_loss: 0.5525 - val_accuracy: 0.7640\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3673 - accuracy: 0.8374 - val_loss: 0.5587 - val_accuracy: 0.7702\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3685 - accuracy: 0.8395 - val_loss: 0.5534 - val_accuracy: 0.7630\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3685 - accuracy: 0.8366 - val_loss: 0.5593 - val_accuracy: 0.7654\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3667 - accuracy: 0.8378 - val_loss: 0.5594 - val_accuracy: 0.7710\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8405 - val_loss: 0.5568 - val_accuracy: 0.7628\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8385 - val_loss: 0.5600 - val_accuracy: 0.7537\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.8378 - val_loss: 0.5581 - val_accuracy: 0.7660\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3659 - accuracy: 0.8374 - val_loss: 0.5563 - val_accuracy: 0.7620\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3647 - accuracy: 0.8394 - val_loss: 0.5566 - val_accuracy: 0.7646\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3627 - accuracy: 0.8393 - val_loss: 0.5635 - val_accuracy: 0.7678\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3636 - accuracy: 0.8378 - val_loss: 0.5600 - val_accuracy: 0.7604\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.3677 - accuracy: 0.8355 - val_loss: 0.5639 - val_accuracy: 0.7688\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.3636 - accuracy: 0.8394 - val_loss: 0.5593 - val_accuracy: 0.7644\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3651 - accuracy: 0.8392 - val_loss: 0.5659 - val_accuracy: 0.7632\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8402 - val_loss: 0.5653 - val_accuracy: 0.7642\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3625 - accuracy: 0.8390 - val_loss: 0.5649 - val_accuracy: 0.7630\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8390 - val_loss: 0.5682 - val_accuracy: 0.7666\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8411 - val_loss: 0.5636 - val_accuracy: 0.7604\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3602 - accuracy: 0.8419 - val_loss: 0.5659 - val_accuracy: 0.7662\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3650 - accuracy: 0.8380 - val_loss: 0.5668 - val_accuracy: 0.7608\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3625 - accuracy: 0.8403 - val_loss: 0.5692 - val_accuracy: 0.7630\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8390 - val_loss: 0.5689 - val_accuracy: 0.7640\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.8387 - val_loss: 0.5685 - val_accuracy: 0.7602\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3576 - accuracy: 0.8426 - val_loss: 0.5686 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3626 - accuracy: 0.8402 - val_loss: 0.5689 - val_accuracy: 0.7589\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3649 - accuracy: 0.8403 - val_loss: 0.5684 - val_accuracy: 0.7632\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3547 - accuracy: 0.8438 - val_loss: 0.5719 - val_accuracy: 0.7557\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3593 - accuracy: 0.8412 - val_loss: 0.5738 - val_accuracy: 0.7664\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3631 - accuracy: 0.8402 - val_loss: 0.5724 - val_accuracy: 0.7638\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8393 - val_loss: 0.5742 - val_accuracy: 0.7626\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.8409 - val_loss: 0.5702 - val_accuracy: 0.7622\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y_train.pickle\", \"rb\")\n",
    "Y_train = pickle.load(pickle_in)\n",
    "#nonzeroind = np.nonzero(Y_train)[0]\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='min', patience=50)\n",
    "NAME = \"NN-{}\".format(int(time.time()))\n",
    "tensorBoard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=30, activation='relu')) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=2500, epochs=200,validation_split=0.1, callbacks=[tensorBoard,early_stop], verbose=1,shuffle=True)\n",
    "model.save('model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  PREDICTION\n",
      "0   0    0.008455\n",
      "1   1    0.106292\n",
      "2   2    0.001918\n",
      "3   3    0.146255\n",
      "4   4    0.028830\n",
      "3162\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "pickle_in = open(\"X_test.pickle\", \"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"IDs.pickle\", \"rb\")\n",
    "IDs = pickle.load(pickle_in)\n",
    "\n",
    "p = model.predict(X_test)\n",
    "p = np.array(p).reshape(-1)\n",
    "IDs = np.array(IDs).reshape(-1)\n",
    "\n",
    "result = pd.DataFrame({'ID': IDs, 'PREDICTION': p})\n",
    "result.to_csv('result.csv', index=False)\n",
    "print(result.head())\n",
    "print(p[p>0.5].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
