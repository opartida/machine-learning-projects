{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow-data-validation\n",
    "%pip install -q tensorflow_data_validation[visualization]\n",
    "%pip install tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFDV version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tempfile\n",
    "import tensorflow_data_validation as tfdv\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = './data'\n",
    "TRAIN_DATA = os.path.join(DATA, 'train.csv')\n",
    "TEST_DATA = os.path.join(DATA, 'test.csv')\n",
    "OUTPUT = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>WEBSITE</th>\n",
       "      <th>GDS</th>\n",
       "      <th>DEPARTURE</th>\n",
       "      <th>ARRIVAL</th>\n",
       "      <th>ADULTS</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>INFANTS</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>HAUL_TYPE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DEVICE</th>\n",
       "      <th>TRIP_TYPE</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>SMS</th>\n",
       "      <th>EXTRA_BAGGAGE</th>\n",
       "      <th>NO_GDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01/July</td>\n",
       "      <td>EDES</td>\n",
       "      <td>1</td>\n",
       "      <td>22/July</td>\n",
       "      <td>25/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>DOMESTIC</td>\n",
       "      <td>628,844</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01/July</td>\n",
       "      <td>EDIT</td>\n",
       "      <td>0</td>\n",
       "      <td>29/July</td>\n",
       "      <td>29/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1281,43</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01/July</td>\n",
       "      <td>OPUK</td>\n",
       "      <td>2</td>\n",
       "      <td>29/July</td>\n",
       "      <td>19/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1730,35</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>01/July</td>\n",
       "      <td>OPIT</td>\n",
       "      <td>0</td>\n",
       "      <td>24/July</td>\n",
       "      <td>04/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>DOMESTIC</td>\n",
       "      <td>652,702</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>MULTI_DESTINATION</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01/July</td>\n",
       "      <td>EDES</td>\n",
       "      <td>0</td>\n",
       "      <td>11/August</td>\n",
       "      <td>11/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1717,85</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>02/July</td>\n",
       "      <td>EDUK</td>\n",
       "      <td>1</td>\n",
       "      <td>02/July</td>\n",
       "      <td>02/July</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1035,13</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>02/July</td>\n",
       "      <td>EDPT</td>\n",
       "      <td>1</td>\n",
       "      <td>11/August</td>\n",
       "      <td>19/August</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1152,2</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>02/July</td>\n",
       "      <td>GOFR</td>\n",
       "      <td>1</td>\n",
       "      <td>09/September</td>\n",
       "      <td>23/September</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>2236,54</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>02/July</td>\n",
       "      <td>EDPT</td>\n",
       "      <td>2</td>\n",
       "      <td>05/July</td>\n",
       "      <td>21/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1312,48</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>02/July</td>\n",
       "      <td>GOFR</td>\n",
       "      <td>0</td>\n",
       "      <td>06/July</td>\n",
       "      <td>06/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>2403,31</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID TIMESTAMP WEBSITE  GDS     DEPARTURE       ARRIVAL  ADULTS  \\\n",
       "0          0   01/July    EDES    1       22/July       25/July       1   \n",
       "1          1   01/July    EDIT    0       29/July       29/July       1   \n",
       "2          2   01/July    OPUK    2       29/July     19/August       1   \n",
       "3          3   01/July    OPIT    0       24/July     04/August       1   \n",
       "4          4   01/July    EDES    0     11/August     11/August       1   \n",
       "...      ...       ...     ...  ...           ...           ...     ...   \n",
       "49995  49995   02/July    EDUK    1       02/July       02/July       2   \n",
       "49996  49996   02/July    EDPT    1     11/August     19/August       2   \n",
       "49997  49997   02/July    GOFR    1  09/September  23/September       1   \n",
       "49998  49998   02/July    EDPT    2       05/July       21/July       1   \n",
       "49999  49999   02/July    GOFR    0       06/July       06/July       1   \n",
       "\n",
       "       CHILDREN  INFANTS  TRAIN         HAUL_TYPE DISTANCE      DEVICE  \\\n",
       "0             0        0  False          DOMESTIC  628,844      TABLET   \n",
       "1             0        0  False       CONTINENTAL  1281,43  SMARTPHONE   \n",
       "2             0        0  False       CONTINENTAL  1730,35      TABLET   \n",
       "3             0        0  False          DOMESTIC  652,702  SMARTPHONE   \n",
       "4             0        0  False       CONTINENTAL  1717,85    COMPUTER   \n",
       "...         ...      ...    ...               ...      ...         ...   \n",
       "49995         0        0  False       CONTINENTAL  1035,13    COMPUTER   \n",
       "49996         1        0  False       CONTINENTAL   1152,2  SMARTPHONE   \n",
       "49997         0        0  False  INTERCONTINENTAL  2236,54  SMARTPHONE   \n",
       "49998         0        0  False       CONTINENTAL  1312,48    COMPUTER   \n",
       "49999         0        0  False  INTERCONTINENTAL  2403,31  SMARTPHONE   \n",
       "\n",
       "               TRIP_TYPE PRODUCT    SMS  EXTRA_BAGGAGE  NO_GDS  \n",
       "0             ROUND_TRIP    TRIP   True          False       0  \n",
       "1                ONE_WAY    TRIP  False          False       1  \n",
       "2             ROUND_TRIP    TRIP   True          False       0  \n",
       "3      MULTI_DESTINATION    TRIP  False          False       2  \n",
       "4                ONE_WAY    TRIP  False          False       1  \n",
       "...                  ...     ...    ...            ...     ...  \n",
       "49995            ONE_WAY    TRIP   True           True       0  \n",
       "49996         ROUND_TRIP    TRIP   True          False       0  \n",
       "49997         ROUND_TRIP    TRIP  False          False       0  \n",
       "49998         ROUND_TRIP    TRIP  False           True       0  \n",
       "49999            ONE_WAY    TRIP  False          False       1  \n",
       "\n",
       "[50000 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>WEBSITE</th>\n",
       "      <th>GDS</th>\n",
       "      <th>DEPARTURE</th>\n",
       "      <th>ARRIVAL</th>\n",
       "      <th>ADULTS</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>INFANTS</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>HAUL_TYPE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DEVICE</th>\n",
       "      <th>TRIP_TYPE</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>SMS</th>\n",
       "      <th>NO_GDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03/July</td>\n",
       "      <td>EDES</td>\n",
       "      <td>1</td>\n",
       "      <td>22/July</td>\n",
       "      <td>22/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>DOMESTIC</td>\n",
       "      <td>3425,95</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/July</td>\n",
       "      <td>GOFR</td>\n",
       "      <td>1</td>\n",
       "      <td>05/July</td>\n",
       "      <td>22/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>3206,92</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/July</td>\n",
       "      <td>OPGB</td>\n",
       "      <td>1</td>\n",
       "      <td>22/July</td>\n",
       "      <td>12/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>6605,22</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03/July</td>\n",
       "      <td>EDUK</td>\n",
       "      <td>0</td>\n",
       "      <td>06/July</td>\n",
       "      <td>08/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1302,29</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ROUND_TRIP</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>03/July</td>\n",
       "      <td>OPDE</td>\n",
       "      <td>1</td>\n",
       "      <td>10/September</td>\n",
       "      <td>10/September</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>6770,78</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>04/July</td>\n",
       "      <td>EDES</td>\n",
       "      <td>0</td>\n",
       "      <td>17/July</td>\n",
       "      <td>17/July</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>1419,8</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>04/July</td>\n",
       "      <td>OPFR</td>\n",
       "      <td>1</td>\n",
       "      <td>06/August</td>\n",
       "      <td>06/August</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>DOMESTIC</td>\n",
       "      <td>1921,41</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>04/July</td>\n",
       "      <td>EDGB</td>\n",
       "      <td>0</td>\n",
       "      <td>09/July</td>\n",
       "      <td>09/July</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CONTINENTAL</td>\n",
       "      <td>804,68</td>\n",
       "      <td>SMARTPHONE</td>\n",
       "      <td>ONE_WAY</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>04/July</td>\n",
       "      <td>GOFR</td>\n",
       "      <td>2</td>\n",
       "      <td>24/July</td>\n",
       "      <td>04/August</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>7341,19</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>MULTI_DESTINATION</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>04/July</td>\n",
       "      <td>EDFR</td>\n",
       "      <td>1</td>\n",
       "      <td>27/July</td>\n",
       "      <td>27/July</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>INTERCONTINENTAL</td>\n",
       "      <td>1062,46</td>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>MULTI_DESTINATION</td>\n",
       "      <td>TRIP</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID TIMESTAMP WEBSITE  GDS     DEPARTURE       ARRIVAL  ADULTS  \\\n",
       "0          0   03/July    EDES    1       22/July       22/July       1   \n",
       "1          1   03/July    GOFR    1       05/July     22/August       1   \n",
       "2          2   03/July    OPGB    1       22/July     12/August       1   \n",
       "3          3   03/July    EDUK    0       06/July       08/July       1   \n",
       "4          4   03/July    OPDE    1  10/September  10/September       1   \n",
       "...      ...       ...     ...  ...           ...           ...     ...   \n",
       "29995  29995   04/July    EDES    0       17/July       17/July       1   \n",
       "29996  29996   04/July    OPFR    1     06/August     06/August       3   \n",
       "29997  29997   04/July    EDGB    0       09/July       09/July       1   \n",
       "29998  29998   04/July    GOFR    2       24/July     04/August       1   \n",
       "29999  29999   04/July    EDFR    1       27/July       27/July       2   \n",
       "\n",
       "       CHILDREN  INFANTS  TRAIN         HAUL_TYPE DISTANCE      DEVICE  \\\n",
       "0             0        0  False          DOMESTIC  3425,95    COMPUTER   \n",
       "1             0        0  False  INTERCONTINENTAL  3206,92  SMARTPHONE   \n",
       "2             0        0  False  INTERCONTINENTAL  6605,22    COMPUTER   \n",
       "3             0        0  False       CONTINENTAL  1302,29  SMARTPHONE   \n",
       "4             0        0  False  INTERCONTINENTAL  6770,78    COMPUTER   \n",
       "...         ...      ...    ...               ...      ...         ...   \n",
       "29995         0        0  False       CONTINENTAL   1419,8    COMPUTER   \n",
       "29996         1        0  False          DOMESTIC  1921,41    COMPUTER   \n",
       "29997         1        0  False       CONTINENTAL   804,68  SMARTPHONE   \n",
       "29998         0        0  False  INTERCONTINENTAL  7341,19    COMPUTER   \n",
       "29999         0        0  False  INTERCONTINENTAL  1062,46    COMPUTER   \n",
       "\n",
       "               TRIP_TYPE PRODUCT    SMS  NO_GDS  \n",
       "0                ONE_WAY    TRIP   True       0  \n",
       "1             ROUND_TRIP    TRIP  False       0  \n",
       "2             ROUND_TRIP    TRIP  False       0  \n",
       "3             ROUND_TRIP    TRIP  False       2  \n",
       "4                ONE_WAY    TRIP   True       0  \n",
       "...                  ...     ...    ...     ...  \n",
       "29995            ONE_WAY    TRIP   True       1  \n",
       "29996            ONE_WAY    TRIP   True       0  \n",
       "29997            ONE_WAY    TRIP  False       1  \n",
       "29998  MULTI_DESTINATION    TRIP   True       1  \n",
       "29999  MULTI_DESTINATION    TRIP   True       1  \n",
       "\n",
       "[30000 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA, sep=\";\")    \n",
    "test_df = pd.read_csv(TEST_DATA, sep=\";\")\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'WEBSITE',\n",
    "    'HAUL_TYPE',\n",
    "    'DEVICE',\n",
    "    'TRIP_TYPE',\n",
    "    'PRODUCT',\n",
    "    'DEPARTURE',\n",
    "    'ARRIVAL',\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    'TIMESTAMP',\n",
    "    'GDS',    \n",
    "    'CHILDREN',\n",
    "    'ADULTS',\n",
    "    'INFANTS',\n",
    "    'DISTANCE',\n",
    "    'SMS',\n",
    "    'NO_GDS',\n",
    "]\n",
    "\n",
    "ORDERED_CSV_COLUMNS = [\n",
    "    'ID',\n",
    "    'TIMESTAMP',\n",
    "    'WEBSITE',\n",
    "    'GDS',\n",
    "    'DEPARTURE',\n",
    "    'ARRIVAL',\n",
    "    'ADULTS',\n",
    "    'CHILDREN',\n",
    "    'INFANTS',\n",
    "    'TRAIN',\n",
    "    'HAUL_TYPE',\n",
    "    'DISTANCE',\n",
    "    'DEVICE',\n",
    "    'TRIP_TYPE',\n",
    "    'PRODUCT',\n",
    "    'SMS',\n",
    "    'NO_GDS'\n",
    "]\n",
    "\n",
    "LABEL_KEY = 'EXTRA_BAGGAGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow_data_validation as tfdv\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
    "train_stats = tfdv.generate_statistics_from_dataframe(train_df)\n",
    "test_stats = tfdv.generate_statistics_from_dataframe(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(train_stats)\n",
    "tfdv.visualize_statistics(lhs_statistics=train_stats,\n",
    "                         rhs_statistics=test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer schema and detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.infer_schema(train_stats)\n",
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "# Create schema environments and remove the label from the testing environment so it is not detected as an anomaly in the test set\n",
    "schema.default_environment.append('TRAINING')\n",
    "schema.default_environment.append('TESTING')\n",
    "\n",
    "tfdv.get_feature(schema, 'EXTRA_BAGGAGE').not_in_environment.append('TESTING')\n",
    "\n",
    "# Generate new statistics based on schema\n",
    "stats_options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True)\n",
    "stats_options.label_feature = 'EXTRA_BAGGAGE'\n",
    "train_stats = tfdv.generate_statistics_from_dataframe(\n",
    "    train_df,\n",
    "    stats_options=stats_options,\n",
    ")\n",
    "\n",
    "# Check for anomalies in the test statistics\n",
    "anomalies = tfdv.validate_statistics(test_stats, schema, environment='TESTING')\n",
    "tfdv.display_anomalies(anomalies)\n",
    "\n",
    "#options = tfdv.StatsOptions(schema=schema)\n",
    "#anomalous_example_stats = tfdv.validate_examples_in_csv(data_location=TRAIN_DATA, stats_options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data skew and drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.get_feature(schema, 'WEBSITE').skew_comparator.infinity_norm.threshold = 0.01\n",
    "skew_anomalies = tfdv.validate_statistics(statistics=train_stats, schema=schema, serving_statistics=test_stats)\n",
    "tfdv.display_anomalies(skew_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate statistics on data slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_data_validation.utils import slicing_util\n",
    "slice_fn =  slicing_util.get_feature_value_slicer(features={'DEVICE': 'COMPUTER'})\n",
    "stats_options = tfdv.StatsOptions(slice_functions=[slice_fn])\n",
    "\n",
    "train_stats = tfdv.generate_statistics_from_dataframe(\n",
    "    train_df,\n",
    "    stats_options=stats_options,\n",
    ")\n",
    "\n",
    "tfdv.visualize_statistics(train_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U tensorflow-transform\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import importlib\n",
    "importlib.reload(pkg_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from tfx_bsl.public import tfxio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of temp files\n",
    "TRANSFORMED_TRAIN_DATA_FILEBASE = 'train_transformed'\n",
    "TRANSFORMED_TEST_DATA_FILEBASE = 'test_transformed'\n",
    "EXPORTED_MODEL_DIR = 'exported_model_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = ['ID', 'TIMESTAMP', 'TRAIN']\n",
    "train_df.drop(DROP_COLS,  axis='columns', inplace=True)\n",
    "test_df.drop(DROP_COLS,  axis='columns', inplace=True)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS = 1\n",
    "def preprocessing_fn(inputs):\n",
    "  outputs = inputs.copy()\n",
    "  # Scale numeric columns to have range [0, 1].\n",
    "  for key in NUMERIC_FEATURE_KEYS:\n",
    "    outputs[key] = tft.scale_to_0_1(inputs[key])\n",
    "\n",
    "  # For all categorical columns except the label column, we generate a\n",
    "  # vocabulary but do not modify the feature.  This vocabulary is instead\n",
    "  # used in the trainer, by means of a feature column, to convert the feature\n",
    "  # from a string to an integer id.\n",
    "  for key in CATEGORICAL_FEATURE_KEYS:\n",
    "    outputs[key] = tft.compute_and_apply_vocabulary(\n",
    "        tft.strings.strip(inputs[key]),\n",
    "        num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "        vocab_filename=key)\n",
    "  \n",
    "  return outputs \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_file, test_data_file, working_dir):\n",
    "  \"\"\"Transform the data and write out as a TFRecord of Example protos.\n",
    "\n",
    "  Read in the data using the CSV reader, and transform it using a\n",
    "  preprocessing pipeline that scales numeric data and converts categorical data\n",
    "  from strings to int64 values indices, by creating a vocabulary for each\n",
    "  category.\n",
    "\n",
    "  Args:\n",
    "    train_data_file: File containing training data\n",
    "    test_data_file: File containing test data\n",
    "    working_dir: Directory to write transformed data and metadata to\n",
    "  \"\"\"\n",
    "\n",
    "  # The \"with\" block will create a pipeline, and run that pipeline at the exit\n",
    "  # of the block.\n",
    "  with tft.beam.Pipeline() as pipeline:\n",
    "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "      # Create a TFXIO to read the census data with the schema. To do this we\n",
    "      # need to list all columns in order since the schema doesn't specify the\n",
    "      # order of columns in the csv.\n",
    "      # We first read CSV files and use BeamRecordCsvTFXIO whose .BeamSource()\n",
    "      # accepts a PCollection[bytes] because we need to patch the records first\n",
    "      # (see \"FixCommasTrainData\" below). Otherwise, tfxio.CsvTFXIO can be used\n",
    "      # to both read the CSV files and parse them to TFT inputs:\n",
    "      # csv_tfxio = tfxio.CsvTFXIO(...)\n",
    "      # raw_data = (pipeline | 'ToRecordBatches' >> csv_tfxio.BeamSource())\n",
    "      train_csv_tfxio = tfxio.CsvTFXIO(\n",
    "          file_pattern=TRAIN_DATA,\n",
    "          telemetry_descriptors=[],\n",
    "          column_names=ORDERED_CSV_COLUMNS,\n",
    "          schema=schema)\n",
    "\n",
    "      # Read in raw data and convert using CSV TFXIO.\n",
    "      raw_data = (\n",
    "          pipeline |\n",
    "          'ReadTrainCsv' >> train_csv_tfxio.BeamSource())\n",
    "\n",
    "      # Combine data and schema into a dataset tuple.  Note that we already used\n",
    "      # the schema to read the CSV data, but we also need it to interpret\n",
    "      # raw_data.\n",
    "      cfg = train_csv_tfxio.TensorAdapterConfig()\n",
    "      raw_dataset = (raw_data, cfg)\n",
    "\n",
    "      # The TFXIO output format is chosen for improved performance.\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | tft_beam.AnalyzeAndTransformDataset(\n",
    "              preprocessing_fn, output_record_batches=True))\n",
    "\n",
    "      # Transformed metadata is not necessary for encoding.\n",
    "      transformed_data, _ = transformed_dataset\n",
    "\n",
    "      # Extract transformed RecordBatches, encode and write them to the given\n",
    "      # directory.\n",
    "      # TODO(b/223384488): Switch to `RecordBatchToExamplesEncoder`.\n",
    "      _ = (\n",
    "          transformed_data\n",
    "          | 'EncodeTrainData' >>\n",
    "          tft.beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n",
    "          | 'WriteTrainData' >> tft.beam.io.WriteToTFRecord(\n",
    "              os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)))\n",
    "\n",
    "      # Now apply transform function to test data.  In this case we remove the\n",
    "      # trailing period at the end of each line, and also ignore the header line\n",
    "      # that is present in the test data file.\n",
    "      test_csv_tfxio = tfxio.CsvTFXIO(\n",
    "          file_pattern=test_data_file,\n",
    "          skip_header_lines=1,\n",
    "          telemetry_descriptors=[],\n",
    "          column_names=ORDERED_CSV_COLUMNS,\n",
    "          schema=schema)\n",
    "      raw_test_data = (\n",
    "          pipeline\n",
    "          | 'ReadTestCsv' >> test_csv_tfxio.BeamSource())\n",
    "\n",
    "      raw_test_dataset = (raw_test_data, test_csv_tfxio.TensorAdapterConfig())\n",
    "\n",
    "      # The TFXIO output format is chosen for improved performance.\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn)\n",
    "          | tft_beam.TransformDataset(output_record_batches=True))\n",
    "\n",
    "      # Transformed metadata is not necessary for encoding.\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "\n",
    "      # Extract transformed RecordBatches, encode and write them to the given\n",
    "      # directory.\n",
    "      _ = (\n",
    "          transformed_test_data\n",
    "          | 'EncodeTestData' >>\n",
    "          tft.beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n",
    "          | 'WriteTestData' >> tft.beam.io.WriteToTFRecord(\n",
    "              os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)))\n",
    "\n",
    "      # Will write a SavedModel and metadata to working_dir, which can then\n",
    "      # be read by the tft.TFTransformOutput class.\n",
    "      _ = (\n",
    "          transform_fn\n",
    "          | 'WriteTransformFn' >> tft_beam.WriteTransformFn(working_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
