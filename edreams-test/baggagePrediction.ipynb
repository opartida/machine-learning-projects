{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow-data-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tensorflow_data_validation[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow_data_validation as tfdv\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = './data'\n",
    "TRAIN_DATA = os.path.join(DATA, 'train.csv')\n",
    "TEST_DATA = os.path.join(DATA, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA, sep=\",\")    \n",
    "test_df = pd.read_csv(TEST_DATA, sep=\",\")\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow_data_validation as tfdv\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
    "train_stats = tfdv.generate_statistics_from_csv(data_location=TRAIN_DATA)\n",
    "test_stats = tfdv.generate_statistics_from_csv(data_location=TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(train_stats)\n",
    "tfdv.visualize_statistics(lhs_statistics=train_stats,\n",
    "                         rhs_statistics=test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'ID'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'TIMESTAMP'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'TIMESTAMP'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'WEBSITE'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'WEBSITE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'GDS'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'DEPARTURE'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'ARRIVAL'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'ADULTS'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'CHILDREN'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'INFANTS'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'TRAIN'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'TRAIN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'HAUL_TYPE'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'HAUL_TYPE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'DISTANCE'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'DEVICE'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>'DEVICE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'TRIP_TYPE'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'TRIP_TYPE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'PRODUCT'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'PRODUCT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'SMS'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'SMS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'EXTRA_BAGGAGE'</th>\n",
       "      <td>STRING</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>'EXTRA_BAGGAGE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'NO_GDS'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>optional</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Type  Presence Valency           Domain\n",
       "Feature name                                              \n",
       "'ID'                INT  required                        -\n",
       "'TIMESTAMP'      STRING  required              'TIMESTAMP'\n",
       "'WEBSITE'        STRING  required                'WEBSITE'\n",
       "'GDS'               INT  required                        -\n",
       "'DEPARTURE'       BYTES  required                        -\n",
       "'ARRIVAL'         BYTES  required                        -\n",
       "'ADULTS'            INT  required                        -\n",
       "'CHILDREN'          INT  required                        -\n",
       "'INFANTS'           INT  required                        -\n",
       "'TRAIN'          STRING  required                  'TRAIN'\n",
       "'HAUL_TYPE'      STRING  required              'HAUL_TYPE'\n",
       "'DISTANCE'        BYTES  required                        -\n",
       "'DEVICE'         STRING  optional  single         'DEVICE'\n",
       "'TRIP_TYPE'      STRING  required              'TRIP_TYPE'\n",
       "'PRODUCT'        STRING  required                'PRODUCT'\n",
       "'SMS'            STRING  required                    'SMS'\n",
       "'EXTRA_BAGGAGE'  STRING  required          'EXTRA_BAGGAGE'\n",
       "'NO_GDS'          FLOAT  optional  single                -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'TIMESTAMP'</th>\n",
       "      <td>'01/July', '02/July'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'WEBSITE'</th>\n",
       "      <td>'EDAE', 'EDAR', 'EDAU', 'EDBR', 'EDCA', 'EDCH', 'EDCL', 'EDCN', 'EDCO', 'EDDE', 'EDEG', 'EDES', 'EDFR', 'EDGB', 'EDGR', 'EDHK', 'EDID', 'EDIN', 'EDIT', 'EDJP', 'EDMA', 'EDMX', 'EDNL', 'EDNZ', 'EDPE', 'EDPH', 'EDPT', 'EDRU', 'EDSG', 'EDTH', 'EDTR', 'EDUK', 'EDUS', 'EDVE', 'EDZA', 'GODE', 'GOES', 'GOFR', 'GOGB', 'GOIT', 'GONL', 'GOPT', 'OPAT', 'OPAU', 'OPCH', 'OPDE', 'OPDEC', 'OPFR', 'OPFRC', 'OPGB', 'OPIT', 'OPNL', 'OPPL', 'OPPLC', 'OPUK', 'TLDK', 'TLDKC', 'TLFI', 'TLNO', 'TLSE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'TRAIN'</th>\n",
       "      <td>'False', 'True'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'HAUL_TYPE'</th>\n",
       "      <td>'CONTINENTAL', 'DOMESTIC', 'INTERCONTINENTAL'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'DEVICE'</th>\n",
       "      <td>'COMPUTER', 'MULTI_DESTINATION', 'ONE_WAY', 'OTHER', 'ROUND_TRIP', 'SMARTPHONE', 'TABLET'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'TRIP_TYPE'</th>\n",
       "      <td>'DYNPACK', 'MULTI_DESTINATION', 'ONE_WAY', 'ROUND_TRIP', 'TRIP'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'PRODUCT'</th>\n",
       "      <td>'DYNPACK', 'False', 'TRIP', 'True'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'SMS'</th>\n",
       "      <td>'False', 'True'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'EXTRA_BAGGAGE'</th>\n",
       "      <td>'0', '1', '2', '3', 'False', 'True'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Values\n",
       "Domain                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "'TIMESTAMP'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    '01/July', '02/July'\n",
       "'WEBSITE'        'EDAE', 'EDAR', 'EDAU', 'EDBR', 'EDCA', 'EDCH', 'EDCL', 'EDCN', 'EDCO', 'EDDE', 'EDEG', 'EDES', 'EDFR', 'EDGB', 'EDGR', 'EDHK', 'EDID', 'EDIN', 'EDIT', 'EDJP', 'EDMA', 'EDMX', 'EDNL', 'EDNZ', 'EDPE', 'EDPH', 'EDPT', 'EDRU', 'EDSG', 'EDTH', 'EDTR', 'EDUK', 'EDUS', 'EDVE', 'EDZA', 'GODE', 'GOES', 'GOFR', 'GOGB', 'GOIT', 'GONL', 'GOPT', 'OPAT', 'OPAU', 'OPCH', 'OPDE', 'OPDEC', 'OPFR', 'OPFRC', 'OPGB', 'OPIT', 'OPNL', 'OPPL', 'OPPLC', 'OPUK', 'TLDK', 'TLDKC', 'TLFI', 'TLNO', 'TLSE'\n",
       "'TRAIN'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             'False', 'True'\n",
       "'HAUL_TYPE'                                                                                                                                                                                                                                                                                                                                                                                                                                                           'CONTINENTAL', 'DOMESTIC', 'INTERCONTINENTAL'\n",
       "'DEVICE'                                                                                                                                                                                                                                                                                                                                                                                                                  'COMPUTER', 'MULTI_DESTINATION', 'ONE_WAY', 'OTHER', 'ROUND_TRIP', 'SMARTPHONE', 'TABLET'\n",
       "'TRIP_TYPE'                                                                                                                                                                                                                                                                                                                                                                                                                                         'DYNPACK', 'MULTI_DESTINATION', 'ONE_WAY', 'ROUND_TRIP', 'TRIP'\n",
       "'PRODUCT'                                                                                                                                                                                                                                                                                                                                                                                                                                                                        'DYNPACK', 'False', 'TRIP', 'True'\n",
       "'SMS'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               'False', 'True'\n",
       "'EXTRA_BAGGAGE'                                                                                                                                                                                                                                                                                                                                                                                                                                                                 '0', '1', '2', '3', 'False', 'True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema = tfdv.infer_schema(train_stats)\n",
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly short description</th>\n",
       "      <th>Anomaly long description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'EXTRA_BAGGAGE'</th>\n",
       "      <td>Non-boolean values</td>\n",
       "      <td>Saw unexpected value \"0\" instead of {}.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'PRODUCT'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: False (&lt;1%), True (&lt;1%).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Anomaly short description  \\\n",
       "Feature name                                \n",
       "'EXTRA_BAGGAGE'        Non-boolean values   \n",
       "'PRODUCT'        Unexpected string values   \n",
       "\n",
       "                                                                   Anomaly long description  \n",
       "Feature name                                                                                 \n",
       "'EXTRA_BAGGAGE'                                     Saw unexpected value \"0\" instead of {}.  \n",
       "'PRODUCT'        Examples contain values missing from the schema: False (<1%), True (<1%).   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "tfdv.set_domain(schema, 'PRODUCT', schema_pb2.StringDomain(name='PRODUCT', value=['DYNPACK', 'TRIP']))\n",
    "tfdv.set_domain(schema, 'EXTRA_BAGGAGE', schema_pb2.BoolDomain())\n",
    "\n",
    "stats_options = tfdv.StatsOptions(schema=schema, infer_type_from_schema=True)\n",
    "\n",
    "train_stats = tfdv.generate_statistics_from_csv(\n",
    "    data_location=TRAIN_DATA,\n",
    "    stats_options=stats_options,\n",
    ")\n",
    "\n",
    "anomalies = tfdv.validate_statistics(train_stats, schema)\n",
    "tfdv.display_anomalies(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ID, TIMESTAMP and TRAIN\n",
    "##### Train is always false so it does not provide information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = ['ID', 'TIMESTAMP', 'TRAIN']\n",
    "train_df.drop(DROP_COLS,  axis='columns', inplace=True)\n",
    "test_df.drop(DROP_COLS,  axis='columns', inplace=True)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with empty fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = {month.lower(): index for index, month in enumerate(calendar.month_name) if month}\n",
    "def replaceMonthName(date):\n",
    "    index = date.find(\"/\")\n",
    "    month_name = f\"{date[index+1:]}\".lower()\n",
    "    return date[:index] + f\"{month_names[month_name]}\".zfill(2)\n",
    "\n",
    "def processDates(data):\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].str.replace(\"-\",\"/\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].str.replace(\"-\",\"/\")\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    \n",
    "processDates(X_train)\n",
    "processDates(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert distance to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['DISTANCE'] = X_train['DISTANCE'].str.strip()\n",
    "X_train['DISTANCE'] = X_train['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_test['DISTANCE'] = X_test['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_train['DISTANCE'] = pd.to_numeric(X_train['DISTANCE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    oe_style = OneHotEncoder(handle_unknown = 'ignore')   \n",
    "    \n",
    "    for col in columns:        \n",
    "        X_train_enc = oe_style.fit_transform(X_train[[col]])\n",
    "        X_train = X_train.join(pd.DataFrame(X_train_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_test_enc = oe_style.transform(X_test[[col]])   \n",
    "        X_test = X_test.join(pd.DataFrame(X_test_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_train = X_train.drop([col], axis=1)\n",
    "        X_test = X_test.drop([col], axis=1)   \n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def binary_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    \n",
    "    for col in columns:   \n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "hot_encode_cols = ['WEBSITE','DEVICE','HAUL_TYPE','TRIP_TYPE', 'PRODUCT']\n",
    "label_encode_cols = ['TRAIN', 'SMS']\n",
    "\n",
    "[X_train, X_test] = hot_encode_categorical_inputs(X_train, X_test, hot_encode_cols)\n",
    "[X_train, X_test] = binary_encode_categorical_inputs(X_train, X_test, label_encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test, columns):\n",
    "    # copy the data\n",
    "    train = X_train.copy()\n",
    "    test = X_test.copy()\n",
    "    normalizer = preprocessing.MinMaxScaler()\n",
    "    for column in columns:\n",
    "        train[column] = normalizer.fit_transform(np.array(train[column]).reshape(-1,1))\n",
    "        test[column] = normalizer.transform(np.array(test[column]).reshape(-1,1))\n",
    "    return train, test\n",
    "    \n",
    "[X_train, X_test] = normalize(X_train, X_test, ['DISTANCE', 'DEPARTURE', 'ARRIVAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)    \n",
    "    y_train_enc = pd.DataFrame(y_train_enc)\n",
    "    return y_train_enc\n",
    "\n",
    "Y_train = X_train['EXTRA_BAGGAGE']\n",
    "X_train = X_train.drop('EXTRA_BAGGAGE',  axis='columns')\n",
    "\n",
    "Y_train = prepare_targets(Y_train)\n",
    "Y_train.isin([1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveData(\"IDs.pickle\", X_test[\"ID\"].values)\n",
    "X_test = X_test.drop('ID',  axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=82)\n",
    "pca.fit(train_df)\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "fig.savefig('Cumulative explained variance.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca_std = np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close() \n",
    "\n",
    "\n",
    "saveData(\"X_train.pickle\", X_train)\n",
    "saveData(\"Y_train.pickle\", Y_train.values)\n",
    "saveData(\"X_test.pickle\", X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from tf.keras.models import Sequential\n",
    "from tf.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tf.keras.callbacks import TensorBoard\n",
    "from tf.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y_train.pickle\", \"rb\")\n",
    "Y_train = pickle.load(pickle_in)\n",
    "#nonzeroind = np.nonzero(Y_train)[0]\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='min', patience=50)\n",
    "NAME = \"NN-{}\".format(int(time.time()))\n",
    "tensorBoard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=30, activation='relu')) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=2500, epochs=200,validation_split=0.1, callbacks=[tensorBoard,early_stop], verbose=1,shuffle=True)\n",
    "model.save('model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "pickle_in = open(\"X_test.pickle\", \"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"IDs.pickle\", \"rb\")\n",
    "IDs = pickle.load(pickle_in)\n",
    "\n",
    "p = model.predict(X_test)\n",
    "p = np.array(p).reshape(-1)\n",
    "IDs = np.array(IDs).reshape(-1)\n",
    "\n",
    "result = pd.DataFrame({'ID': IDs, 'PREDICTION': p})\n",
    "result.to_csv('result.csv', index=False)\n",
    "print(result.head())\n",
    "print(p[p>0.5].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
