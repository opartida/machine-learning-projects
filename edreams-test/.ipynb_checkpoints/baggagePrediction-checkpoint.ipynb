{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, calendar\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train.csv\", sep=\";\")    \n",
    "X_test = pd.read_csv(\"test.csv\", sep=\";\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('ID',  axis='columns')\n",
    "X_test = X_test.drop('ID',  axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with empty fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = {month.lower(): index for index, month in enumerate(calendar.month_name) if month}\n",
    "def replaceMonthName(date):\n",
    "    index = date.find(\"/\")\n",
    "    month_name = f\"{date[index+1:]}\".lower()\n",
    "    return date[:index] + f\"{month_names[month_name]}\".zfill(2)\n",
    "\n",
    "def processDates(data):\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].str.replace(\"-\",\"/\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].str.replace(\"-\",\"/\")\n",
    "    data['TIMESTAMP'] = data['TIMESTAMP'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    data['DEPARTURE'] = data['DEPARTURE'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    data['ARRIVAL'] = data['ARRIVAL'].apply(lambda x: f\"{replaceMonthName(x)}\")\n",
    "    \n",
    "processDates(X_train)\n",
    "processDates(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert distance to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['DISTANCE'] = X_train['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_test['DISTANCE'] = X_test['DISTANCE'].apply(lambda x: x.replace(',','.'))\n",
    "X_train['DISTANCE'] = pd.to_numeric(X_train['DISTANCE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oliver\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def hot_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    oe_style = OneHotEncoder(handle_unknown = 'ignore')   \n",
    "    \n",
    "    for col in columns:        \n",
    "        X_train_enc = oe_style.fit_transform(X_train[[col]])\n",
    "        X_train = X_train.join(pd.DataFrame(X_train_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_test_enc = oe_style.transform(X_test[[col]])   \n",
    "        X_test = X_test.join(pd.DataFrame(X_test_enc.toarray(), columns=oe_style.categories_))\n",
    "        X_train = X_train.drop([col], axis=1)\n",
    "        X_test = X_test.drop([col], axis=1)   \n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def label_encode_categorical_inputs(X_train, X_test, columns):\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:   \n",
    "        X_train_enc = le.fit_transform(X_train[[col]])\n",
    "        X_train = X_train.drop([col], axis=1)\n",
    "        X_train = X_train.join(pd.DataFrame(X_train_enc, columns=[col]))\n",
    "        \n",
    "        X_test_enc = le.fit_transform(X_test[[col]])\n",
    "        X_test = X_test.drop([col], axis=1)\n",
    "        X_test = X_test.join(pd.DataFrame(X_test_enc, columns=[col]))  \n",
    "        \n",
    "    return X_train, X_test\n",
    "\n",
    "hot_encode_cols = ['WEBSITE','DEVICE','HAUL_TYPE','TRIP_TYPE', 'PRODUCT']\n",
    "label_encode_cols = ['TRAIN', 'SMS']\n",
    "\n",
    "[X_train, X_test] = hot_encode_categorical_inputs(X_train, X_test, hot_encode_cols)\n",
    "[X_train, X_test] = label_encode_categorical_inputs(X_train, X_test, label_encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizer = Normalizer()\n",
    "#X_train['DISTANCE']= pd.DataFrame(normalizer.fit_transform(X_train[['DISTANCE']])) \n",
    "#X_test['DISTANCE']= pd.DataFrame(normalizer.transform(X_test[['DISTANCE']]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TIMESTAMP  GDS DEPARTURE ARRIVAL  ADULTS  CHILDREN  INFANTS  DISTANCE  \\\n",
      "0       0107    1      2207    2507       1         0        0   628.844   \n",
      "1       0107    0      2907    2907       1         0        0  1281.430   \n",
      "2       0107    2      2907    1908       1         0        0  1730.350   \n",
      "3       0107    0      2407    0408       1         0        0   652.702   \n",
      "4       0107    0      1108    1108       1         0        0  1717.850   \n",
      "..       ...  ...       ...     ...     ...       ...      ...       ...   \n",
      "95      0107    0      1007    1107       1         0        0  1246.350   \n",
      "96      0107    0      1309    2309       2         0        0  1342.250   \n",
      "97      0107    1      0407    2207       1         0        0  1753.880   \n",
      "98      0107    1      0908    3008       1         1        0  2611.920   \n",
      "99      0107    1      3107    0608       2         0        0   671.543   \n",
      "\n",
      "    NO_GDS  (EDAE,)  ...  (CONTINENTAL,)  (DOMESTIC,)  (INTERCONTINENTAL,)  \\\n",
      "0        0      0.0  ...             0.0          1.0                  0.0   \n",
      "1        1      0.0  ...             1.0          0.0                  0.0   \n",
      "2        0      0.0  ...             1.0          0.0                  0.0   \n",
      "3        2      0.0  ...             0.0          1.0                  0.0   \n",
      "4        1      0.0  ...             1.0          0.0                  0.0   \n",
      "..     ...      ...  ...             ...          ...                  ...   \n",
      "95       2      0.0  ...             1.0          0.0                  0.0   \n",
      "96       1      0.0  ...             1.0          0.0                  0.0   \n",
      "97       1      0.0  ...             0.0          0.0                  1.0   \n",
      "98       1      0.0  ...             0.0          0.0                  1.0   \n",
      "99       1      0.0  ...             0.0          1.0                  0.0   \n",
      "\n",
      "    (MULTI_DESTINATION,)  (ONE_WAY,)  (ROUND_TRIP,)  (DYNPACK,)  (TRIP,)  \\\n",
      "0                    0.0         0.0            1.0         0.0      1.0   \n",
      "1                    0.0         1.0            0.0         0.0      1.0   \n",
      "2                    0.0         0.0            1.0         0.0      1.0   \n",
      "3                    1.0         0.0            0.0         0.0      1.0   \n",
      "4                    0.0         1.0            0.0         0.0      1.0   \n",
      "..                   ...         ...            ...         ...      ...   \n",
      "95                   0.0         0.0            1.0         0.0      1.0   \n",
      "96                   0.0         0.0            1.0         0.0      1.0   \n",
      "97                   1.0         0.0            0.0         0.0      1.0   \n",
      "98                   0.0         0.0            1.0         0.0      1.0   \n",
      "99                   0.0         0.0            1.0         0.0      1.0   \n",
      "\n",
      "    TRAIN  SMS  \n",
      "0     0.0  1.0  \n",
      "1     0.0  0.0  \n",
      "2     0.0  1.0  \n",
      "3     0.0  0.0  \n",
      "4     0.0  0.0  \n",
      "..    ...  ...  \n",
      "95    0.0  1.0  \n",
      "96    0.0  0.0  \n",
      "97    0.0  0.0  \n",
      "98    0.0  0.0  \n",
      "99    0.0  1.0  \n",
      "\n",
      "[100 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "def prepare_targets(y_train):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)    \n",
    "    y_train_enc = pd.DataFrame(y_train_enc)\n",
    "    return y_train_enc\n",
    "\n",
    "Y_train = X_train['EXTRA_BAGGAGE']\n",
    "X_train = X_train.drop('EXTRA_BAGGAGE',  axis='columns')\n",
    "\n",
    "Y_train = prepare_targets(Y_train)\n",
    "print(X_train.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(filename, data):\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close() \n",
    "    \n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "\n",
    "saveData(\"X_train.pickle\", X_train)\n",
    "saveData(\"Y_train.pickle\", Y_train)\n",
    "saveData(\"X_test.pickle\", X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "88/88 [==============================] - 2s 17ms/step - loss: 37.1596 - accuracy: 0.6699 - val_loss: 2.2821 - val_accuracy: 0.7949\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 2.4855 - accuracy: 0.7085 - val_loss: 1.4691 - val_accuracy: 0.7503\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8488 - accuracy: 0.7063 - val_loss: 0.7363 - val_accuracy: 0.7690\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.3095 - accuracy: 0.7142 - val_loss: 1.5663 - val_accuracy: 0.7975\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8797 - accuracy: 0.7151 - val_loss: 0.9122 - val_accuracy: 0.7585\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.5041 - accuracy: 0.7175 - val_loss: 1.6992 - val_accuracy: 0.6311\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.7182 - accuracy: 0.7112 - val_loss: 1.4980 - val_accuracy: 0.4403\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.5878 - accuracy: 0.6933 - val_loss: 0.9121 - val_accuracy: 0.7595\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.4955 - accuracy: 0.7081 - val_loss: 1.9093 - val_accuracy: 0.7979\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8299 - accuracy: 0.7204 - val_loss: 2.5954 - val_accuracy: 0.7979\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7901 - accuracy: 0.7129 - val_loss: 0.9899 - val_accuracy: 0.7899\n"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y_train.pickle\", \"rb\")\n",
    "Y_train = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='min', patience=10)\n",
    "NAME = \"NN-{}\".format(int(time.time()))\n",
    "tensorBoard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=83, activation='relu')) \n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=512, epochs=200,validation_split=0.1, callbacks=[tensorBoard,early_stop], verbose=1,shuffle=True)\n",
    "model.save('model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-ensorboard 2.5.0\n",
      "tensorboard-plugin-wit 1.8.0\n",
      "tensorboard 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins'):\n",
    "    print(entry_point.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "pickle_in = open(\"X_test.pickle\", \"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "p = model.predict(X_test)\n",
    "print(p[p>0.5].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
